{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "polished-aviation",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import networkx as nx\n",
    "\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "from sklearn.cluster import KMeans, MeanShift, DBSCAN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from sklearn import tree, linear_model\n",
    "\n",
    "import scipy.cluster.hierarchy as hierarchy\n",
    "from sklearn.cluster import AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "import umap\n",
    "\n",
    "from torch_geometric.nn import GNNExplainer\n",
    "\n",
    "from utilities import *\n",
    "from heuristics import *\n",
    "from activation_classifier import *\n",
    "import random\n",
    "import models\n",
    "\n",
    "set_rc_params()\n",
    "\n",
    "# ensure reproducibility\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "positive-design",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# general parameters\n",
    "dataset_name = \"BA_Shapes\"\n",
    "\n",
    "model_type = BA_Shapes_GCN\n",
    "load_pretrained = True\n",
    "\n",
    "# hyperparameters\n",
    "k = 10\n",
    "\n",
    "# other parameters\n",
    "train_test_split = 0.8\n",
    "num_hidden_units = 20\n",
    "num_classes = 4\n",
    "\n",
    "epochs = 2500\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reverse-exposure",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Node Classification\n",
      "Number of features:  700\n",
      "Number of labels:  700\n",
      "Number of classes:  700\n",
      "Number of edges:  2\n",
      "Loading pretrained model...\n"
     ]
    }
   ],
   "source": [
    "paths = prepare_output_paths(dataset_name, k)\n",
    "\n",
    "G, labels = load_syn_data(dataset_name)\n",
    "data = prepare_syn_data(G, labels, train_test_split)\n",
    "model = model_type(data[\"x\"].shape[1], num_hidden_units, num_classes, \"BA-Shapes\")\n",
    "\n",
    "if load_pretrained:\n",
    "    print(\"Loading pretrained model...\")\n",
    "    model.load_state_dict(torch.load(os.path.join(paths['base'], \"model.pkl\")))\n",
    "    model.eval()\n",
    "    \n",
    "    with open(os.path.join(paths['base'], \"activations.txt\"), 'rb') as file:\n",
    "        activation_list = pickle.loads(file.read())\n",
    "        \n",
    "else:\n",
    "    model.apply(weights_init)\n",
    "    train(model, data, epochs, lr, paths['base'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "genetic-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "from math import sqrt\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import k_hop_subgraph, to_networkx\n",
    "\n",
    "\n",
    "EPS = 1e-15\n",
    "\n",
    "\n",
    "class GNNExplainer(torch.nn.Module):\n",
    "    r\"\"\"The GNN-Explainer model from the `\"GNNExplainer: Generating\n",
    "    Explanations for Graph Neural Networks\"\n",
    "    <https://arxiv.org/abs/1903.03894>`_ paper for identifying compact subgraph\n",
    "    structures and small subsets node features that play a crucial role in a\n",
    "    GNN’s node-predictions.\n",
    "\n",
    "    .. note::\n",
    "\n",
    "        For an example of using GNN-Explainer, see `examples/gnn_explainer.py\n",
    "        <https://github.com/rusty1s/pytorch_geometric/blob/master/examples/\n",
    "        gnn_explainer.py>`_.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The GNN module to explain.\n",
    "        epochs (int, optional): The number of epochs to train.\n",
    "            (default: :obj:`100`)\n",
    "        lr (float, optional): The learning rate to apply.\n",
    "            (default: :obj:`0.01`)\n",
    "        num_hops (int, optional): The number of hops the :obj:`model` is\n",
    "            aggregating information from.\n",
    "            If set to :obj:`None`, will automatically try to detect this\n",
    "            information based on the number of\n",
    "            :class:`~torch_geometric.nn.conv.message_passing.MessagePassing`\n",
    "            layers inside :obj:`model`. (default: :obj:`None`)\n",
    "        return_type (str, optional): Denotes the type of output from\n",
    "            :obj:`model`. Valid inputs are :obj:`\"log_prob\"` (the model returns\n",
    "            the logarithm of probabilities), :obj:`\"prob\"` (the model returns\n",
    "            probabilities) and :obj:`\"raw\"` (the model returns raw scores).\n",
    "            (default: :obj:`\"log_prob\"`)\n",
    "        log (bool, optional): If set to :obj:`False`, will not log any learning\n",
    "            progress. (default: :obj:`True`)\n",
    "    \"\"\"\n",
    "\n",
    "    coeffs = {\n",
    "        'edge_size': 0.005,\n",
    "        'edge_reduction': 'sum',\n",
    "        'node_feat_size': 1.0,\n",
    "        'node_feat_reduction': 'mean',\n",
    "        'edge_ent': 1.0,\n",
    "        'node_feat_ent': 0.1,\n",
    "    }\n",
    "\n",
    "    def __init__(self, model, epochs: int = 100, lr: float = 0.01,\n",
    "                 num_hops: Optional[int] = None, return_type: str = 'log_prob',\n",
    "                 log: bool = True):\n",
    "        super(GNNExplainer, self).__init__()\n",
    "        assert return_type in ['log_prob', 'prob', 'raw']\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.__num_hops__ = num_hops\n",
    "        self.return_type = return_type\n",
    "        self.log = log\n",
    "\n",
    "    def __set_masks__(self, x, edge_index, init=\"normal\"):\n",
    "        (N, F), E = x.size(), edge_index.size(1)\n",
    "\n",
    "        std = 0.1\n",
    "        self.node_feat_mask = torch.nn.Parameter(torch.randn(F) * 0.1)\n",
    "\n",
    "        std = torch.nn.init.calculate_gain('relu') * sqrt(2.0 / (2 * N))\n",
    "        self.edge_mask = torch.nn.Parameter(torch.randn(E) * std)\n",
    "\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module.__explain__ = True\n",
    "                module.__edge_mask__ = self.edge_mask\n",
    "\n",
    "    def __clear_masks__(self):\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module.__explain__ = False\n",
    "                module.__edge_mask__ = None\n",
    "        self.node_feat_masks = None\n",
    "        self.edge_mask = None\n",
    "\n",
    "    @property\n",
    "    def num_hops(self):\n",
    "        if self.__num_hops__ is not None:\n",
    "            return self.__num_hops__\n",
    "\n",
    "        k = 0\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                k += 1\n",
    "        return k\n",
    "\n",
    "    def __flow__(self):\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                return module.flow\n",
    "        return 'source_to_target'\n",
    "\n",
    "    def __subgraph__(self, node_idx, x, edge_index, **kwargs):\n",
    "        num_nodes, num_edges = x.size(0), edge_index.size(1)\n",
    "\n",
    "        subset, edge_index, mapping, edge_mask = k_hop_subgraph(\n",
    "            node_idx, self.num_hops, edge_index, relabel_nodes=True,\n",
    "            num_nodes=num_nodes, flow=self.__flow__())\n",
    "\n",
    "        x = x[subset]\n",
    "        for key, item in kwargs.items():\n",
    "            if torch.is_tensor(item) and item.size(0) == num_nodes:\n",
    "                item = item[subset]\n",
    "            elif torch.is_tensor(item) and item.size(0) == num_edges:\n",
    "                item = item[edge_mask]\n",
    "            kwargs[key] = item\n",
    "\n",
    "        return x, edge_index, mapping, edge_mask, kwargs\n",
    "\n",
    "    def __loss__(self, node_idx, log_logits, pred_label):\n",
    "        # node_idx is -1 for explaining graphs\n",
    "        \n",
    "#         pred_label = torch.reshape(pred_label, (1,))\n",
    "        print(\"Node_idx \", node_idx)\n",
    "        print(\"log_logits \", log_logits.shape)\n",
    "        print(\"pred label \", pred_label.shape)\n",
    "        \n",
    "        loss = -log_logits[node_idx, pred_label[node_idx]] if node_idx == -1 else -log_logits[0, pred_label[0]]\n",
    "\n",
    "        print(\"Loss 1 \", loss)\n",
    "        \n",
    "        \n",
    "        m = self.edge_mask.sigmoid()\n",
    "        edge_reduce = getattr(torch, self.coeffs['edge_reduction'])\n",
    "        loss = loss + self.coeffs['edge_size'] * edge_reduce(m)\n",
    "        ent = -m * torch.log(m + EPS) - (1 - m) * torch.log(1 - m + EPS)\n",
    "        loss = loss + self.coeffs['edge_ent'] * ent.mean()\n",
    "\n",
    "        m = self.node_feat_mask.sigmoid()\n",
    "        node_feat_reduce = getattr(torch, self.coeffs['node_feat_reduction'])\n",
    "        loss = loss + self.coeffs['node_feat_size'] * node_feat_reduce(m)\n",
    "        ent = -m * torch.log(m + EPS) - (1 - m) * torch.log(1 - m + EPS)\n",
    "        loss = loss + self.coeffs['node_feat_ent'] * ent.mean()\n",
    "        \n",
    "        print(\"Loss 2 \", loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def __to_log_prob__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.log_softmax(dim=-1) if self.return_type == 'raw' else x\n",
    "        x = x.log() if self.return_type == 'prob' else x\n",
    "        return x\n",
    "\n",
    "    def explain_graph(self, x, edge_index, **kwargs):\n",
    "        r\"\"\"Learns and returns a node feature mask and an edge mask that play a\n",
    "        crucial role to explain the prediction made by the GNN for a graph.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): The node feature matrix.\n",
    "            edge_index (LongTensor): The edge indices.\n",
    "            **kwargs (optional): Additional arguments passed to the GNN module.\n",
    "\n",
    "        :rtype: (:class:`Tensor`, :class:`Tensor`)\n",
    "        \"\"\"\n",
    "\n",
    "        self.model.eval()\n",
    "        self.__clear_masks__()\n",
    "\n",
    "        # all nodes belong to same graph\n",
    "        batch = torch.zeros(x.shape[0], dtype=int, device=x.device)\n",
    "\n",
    "        # Get the initial prediction.\n",
    "        with torch.no_grad():\n",
    "            out = self.model(x=x, edge_index=edge_index, batch=batch, **kwargs)\n",
    "            log_logits = self.__to_log_prob__(out)\n",
    "            pred_label = log_logits.argmax(dim=-1)\n",
    "\n",
    "        self.__set_masks__(x, edge_index)\n",
    "        self.to(x.device)\n",
    "\n",
    "        optimizer = torch.optim.Adam([self.node_feat_mask, self.edge_mask],\n",
    "                                     lr=self.lr)\n",
    "\n",
    "        if self.log:  # pragma: no cover\n",
    "            pbar = tqdm(total=self.epochs)\n",
    "            pbar.set_description('Explain graph')\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            optimizer.zero_grad()\n",
    "            h = x * self.node_feat_mask.view(1, -1).sigmoid()\n",
    "            out = self.model(x=h, edge_index=edge_index, batch=batch, **kwargs)\n",
    "            log_logits = self.__to_log_prob__(out)\n",
    "            loss = self.__loss__(-1, log_logits, pred_label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if self.log:  # pragma: no cover\n",
    "                pbar.update(1)\n",
    "\n",
    "        if self.log:  # pragma: no cover\n",
    "            pbar.close()\n",
    "\n",
    "        node_feat_mask = self.node_feat_mask.detach().sigmoid()\n",
    "        edge_mask = self.edge_mask.detach().sigmoid()\n",
    "\n",
    "        self.__clear_masks__()\n",
    "        return node_feat_mask, edge_mask\n",
    "\n",
    "\n",
    "    def explain_node(self, node_idx, x, edge_index, **kwargs):\n",
    "        r\"\"\"Learns and returns a node feature mask and an edge mask that play a\n",
    "        crucial role to explain the prediction made by the GNN for node\n",
    "        :attr:`node_idx`.\n",
    "\n",
    "        Args:\n",
    "            node_idx (int): The node to explain.\n",
    "            x (Tensor): The node feature matrix.\n",
    "            edge_index (LongTensor): The edge indices.\n",
    "            **kwargs (optional): Additional arguments passed to the GNN module.\n",
    "\n",
    "        :rtype: (:class:`Tensor`, :class:`Tensor`)\n",
    "        \"\"\"\n",
    "\n",
    "        self.model.eval()\n",
    "        self.__clear_masks__()\n",
    "        \n",
    "        \n",
    "        print(\"NUMBER OF HOPS \", self.num_hops)\n",
    "\n",
    "        num_edges = edge_index.size(1)\n",
    "\n",
    "        # Only operate on a k-hop subgraph around `node_idx`.\n",
    "        x, edge_index, mapping, hard_edge_mask, kwargs = self.__subgraph__(\n",
    "            node_idx, x, edge_index, **kwargs)\n",
    "        \n",
    "        print(\"THIS IS THE SIZE OF X \", x.shape)\n",
    "\n",
    "        # Get the initial prediction.\n",
    "        with torch.no_grad():\n",
    "            out = self.model(x=x, edge_index=edge_index, **kwargs)\n",
    "            print(\"Output \", out)\n",
    "            log_logits = self.__to_log_prob__(out)\n",
    "            pred_label = log_logits.argmax(dim=-1)\n",
    "\n",
    "        self.__set_masks__(x, edge_index)\n",
    "        self.to(x.device)\n",
    "\n",
    "        optimizer = torch.optim.Adam([self.node_feat_mask, self.edge_mask],\n",
    "                                     lr=self.lr)\n",
    "\n",
    "        if self.log:  # pragma: no cover\n",
    "            pbar = tqdm(total=self.epochs)\n",
    "            pbar.set_description(f'Explain node {node_idx}')\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            optimizer.zero_grad()\n",
    "            h = x * self.node_feat_mask.view(1, -1).sigmoid()\n",
    "            \n",
    "            out = self.model(x=h, edge_index=edge_index, **kwargs)\n",
    "            print(\"Output \", out.shape)\n",
    "            \n",
    "            log_logits = self.__to_log_prob__(out)\n",
    "            loss = self.__loss__(mapping, log_logits, pred_label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if self.log:  # pragma: no cover\n",
    "                pbar.update(1)\n",
    "\n",
    "        if self.log:  # pragma: no cover\n",
    "            pbar.close()\n",
    "\n",
    "        node_feat_mask = self.node_feat_mask.detach().sigmoid()\n",
    "        edge_mask = self.edge_mask.new_zeros(num_edges)\n",
    "        edge_mask[hard_edge_mask] = self.edge_mask.detach().sigmoid()\n",
    "\n",
    "        self.__clear_masks__()\n",
    "\n",
    "        return node_feat_mask, edge_mask\n",
    "\n",
    "\n",
    "    def visualize_subgraph(self, node_idx, edge_index, edge_mask, y=None,\n",
    "                           threshold=None, **kwargs):\n",
    "        r\"\"\"Visualizes the subgraph given an edge mask\n",
    "        :attr:`edge_mask`.\n",
    "\n",
    "        Args:\n",
    "            node_idx (int): The node id to explain.\n",
    "                Set to :obj:`-1` to explain graph.\n",
    "            edge_index (LongTensor): The edge indices.\n",
    "            edge_mask (Tensor): The edge mask.\n",
    "            y (Tensor, optional): The ground-truth node-prediction labels used\n",
    "                as node colorings. All nodes will have the same color\n",
    "                if :attr:`node_idx` is :obj:`-1`.(default: :obj:`None`).\n",
    "            threshold (float, optional): Sets a threshold for visualizing\n",
    "                important edges. If set to :obj:`None`, will visualize all\n",
    "                edges with transparancy indicating the importance of edges.\n",
    "                (default: :obj:`None`)\n",
    "            **kwargs (optional): Additional arguments passed to\n",
    "                :func:`nx.draw`.\n",
    "\n",
    "        :rtype: :class:`matplotlib.axes.Axes`, :class:`networkx.DiGraph`\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        assert edge_mask.size(0) == edge_index.size(1)\n",
    "\n",
    "        if node_idx == -1:\n",
    "            hard_edge_mask = torch.BoolTensor([True] * edge_index.size(1),\n",
    "                                              device=edge_mask.device)\n",
    "            subset = torch.arange(edge_index.max().item() + 1,\n",
    "                                  device=edge_index.device)\n",
    "            y = None\n",
    "\n",
    "        else:\n",
    "            # Only operate on a k-hop subgraph around `node_idx`.\n",
    "            subset, edge_index, _, hard_edge_mask = k_hop_subgraph(\n",
    "                node_idx, self.num_hops, edge_index, relabel_nodes=True,\n",
    "                num_nodes=None, flow=self.__flow__())\n",
    "\n",
    "        edge_mask = edge_mask[hard_edge_mask]\n",
    "\n",
    "        if threshold is not None:\n",
    "            edge_mask = (edge_mask >= threshold).to(torch.float)\n",
    "\n",
    "        if y is None:\n",
    "            y = torch.zeros(edge_index.max().item() + 1,\n",
    "                            device=edge_index.device)\n",
    "        else:\n",
    "            y = y[subset].to(torch.float) / y.max().item()\n",
    "\n",
    "        data = Data(edge_index=edge_index, att=edge_mask, y=y,\n",
    "                    num_nodes=y.size(0)).to('cpu')\n",
    "        G = to_networkx(data, node_attrs=['y'], edge_attrs=['att'])\n",
    "        mapping = {k: i for k, i in enumerate(subset.tolist())}\n",
    "        G = nx.relabel_nodes(G, mapping)\n",
    "\n",
    "        node_kwargs = copy(kwargs)\n",
    "        node_kwargs['node_size'] = kwargs.get('node_size') or 800\n",
    "        node_kwargs['cmap'] = kwargs.get('cmap') or 'cool'\n",
    "\n",
    "        label_kwargs = copy(kwargs)\n",
    "        label_kwargs['font_size'] = kwargs.get('font_size') or 10\n",
    "\n",
    "        pos = nx.spring_layout(G)\n",
    "        ax = plt.gca()\n",
    "        for source, target, data in G.edges(data=True):\n",
    "            ax.annotate(\n",
    "                '', xy=pos[target], xycoords='data', xytext=pos[source],\n",
    "                textcoords='data', arrowprops=dict(\n",
    "                    arrowstyle=\"->\",\n",
    "                    alpha=max(data['att'], 0.1),\n",
    "                    shrinkA=sqrt(node_kwargs['node_size']) / 2.0,\n",
    "                    shrinkB=sqrt(node_kwargs['node_size']) / 2.0,\n",
    "                    connectionstyle=\"arc3,rad=0.1\",\n",
    "                ))\n",
    "        nx.draw_networkx_nodes(G, pos, node_color=y.tolist(), **node_kwargs)\n",
    "        nx.draw_networkx_labels(G, pos, **label_kwargs)\n",
    "\n",
    "        return ax, G\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "surrounded-health",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:   1%|          | 12/1000 [00:00<00:08, 115.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF HOPS  4\n",
      "THIS IS THE SIZE OF X  torch.Size([47, 1])\n",
      "Output  tensor([[-3.5514e-01, -4.0401e+00, -1.2690e+00, -8.4444e+00],\n",
      "        [-3.5514e-01, -4.0401e+00, -1.2690e+00, -8.4444e+00],\n",
      "        [-3.5514e-01, -4.0401e+00, -1.2690e+00, -8.4444e+00],\n",
      "        [-3.5514e-01, -4.0401e+00, -1.2690e+00, -8.4444e+00],\n",
      "        [-3.5514e-01, -4.0401e+00, -1.2690e+00, -8.4444e+00],\n",
      "        [-6.5660e-03, -1.4175e+01, -5.0297e+00, -1.2618e+01],\n",
      "        [-3.2170e-03, -1.3197e+01, -5.7431e+00, -1.2187e+01],\n",
      "        [-2.7321e-03, -1.1023e+01, -5.9212e+00, -1.0413e+01],\n",
      "        [-5.3591e-03, -7.5801e+00, -5.5027e+00, -7.1845e+00],\n",
      "        [-2.0141e-02, -7.1684e+00, -4.0988e+00, -5.9611e+00],\n",
      "        [-6.9588e-03, -7.3223e+00, -5.2669e+00, -6.7995e+00],\n",
      "        [-3.0662e-03, -6.7675e+00, -7.4405e+00, -6.6271e+00],\n",
      "        [-1.2430e-02, -6.3656e+00, -4.8856e+00, -5.7831e+00],\n",
      "        [-1.0825e-03, -7.8289e+00, -9.0292e+00, -7.4806e+00],\n",
      "        [-1.0108e-04, -9.8119e+00, -1.2338e+01, -1.0083e+01],\n",
      "        [-1.5847e-03, -7.4898e+00, -8.4726e+00, -7.1115e+00],\n",
      "        [-2.7635e-03, -6.9357e+00, -7.6820e+00, -6.6254e+00],\n",
      "        [-2.0067e-02, -5.5365e+00, -5.2873e+00, -4.5216e+00],\n",
      "        [-7.4419e-04, -8.3609e+00, -9.8739e+00, -7.6872e+00],\n",
      "        [-4.5143e-02, -4.8885e+00, -4.0146e+00, -3.9869e+00],\n",
      "        [-1.6128e-03, -7.5710e+00, -8.6011e+00, -6.9993e+00],\n",
      "        [-2.2033e-03, -7.3032e+00, -8.3084e+00, -6.6601e+00],\n",
      "        [-2.6383e-02, -5.3597e+00, -5.0092e+00, -4.2227e+00],\n",
      "        [-1.9850e-02, -5.6036e+00, -5.3396e+00, -4.4944e+00],\n",
      "        [-1.3038e-02, -6.1078e+00, -6.1786e+00, -4.7496e+00],\n",
      "        [-8.5469e-05, -1.0163e+01, -1.2899e+01, -1.0025e+01],\n",
      "        [-1.0753e-02, -6.2380e+00, -6.3028e+00, -4.9747e+00],\n",
      "        [-1.5675e-02, -5.8483e+00, -5.8041e+00, -4.6405e+00],\n",
      "        [-6.0492e-04, -8.6614e+00, -1.0382e+01, -7.8223e+00],\n",
      "        [-1.9155e-04, -9.2887e+00, -1.1715e+01, -9.3066e+00],\n",
      "        [-3.1972e-03, -6.8958e+00, -7.7895e+00, -6.3390e+00],\n",
      "        [-8.5043e-04, -8.3668e+00, -1.0051e+01, -7.4622e+00],\n",
      "        [-2.6115e-04, -9.1063e+00, -1.1466e+01, -8.8759e+00],\n",
      "        [-1.0061e-04, -9.9394e+00, -1.2720e+01, -9.9169e+00],\n",
      "        [-1.0359e-04, -9.9855e+00, -1.2567e+01, -9.8236e+00],\n",
      "        [-3.0741e-03, -6.9305e+00, -7.7655e+00, -6.3963e+00],\n",
      "        [-7.3311e-05, -1.0345e+01, -1.3199e+01, -1.0147e+01],\n",
      "        [-5.6762e-03, -6.1077e+00, -7.2978e+00, -5.8935e+00],\n",
      "        [-1.3589e-04, -9.7005e+00, -1.2451e+01, -9.5580e+00],\n",
      "        [-4.2751e-04, -8.6683e+00, -1.0794e+01, -8.3560e+00],\n",
      "        [-8.4103e-04, -8.3804e+00, -9.9747e+00, -7.4791e+00],\n",
      "        [-1.1010e-03, -8.1189e+00, -9.7126e+00, -7.2061e+00],\n",
      "        [-4.1703e-04, -8.5026e+00, -1.0685e+01, -8.5627e+00],\n",
      "        [-2.9571e-04, -9.1904e+00, -1.1920e+01, -8.5848e+00],\n",
      "        [-1.4676e-03, -7.9989e+00, -9.6346e+00, -6.8445e+00],\n",
      "        [-8.9927e-04, -7.0548e+00, -1.5182e+01, -1.0249e+01],\n",
      "        [-2.4956e-02, -4.9391e+00, -5.8515e+00, -4.2260e+00]])\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(24.7137, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(26.5087, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(24.4290, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(26.2238, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(24.1444, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(25.9390, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(23.8599, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(25.6544, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(23.5755, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(25.3698, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(23.2914, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(25.0854, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(23.0074, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(24.8011, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(22.7236, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(24.5170, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(22.4400, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(24.2331, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(22.1566, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(23.9493, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(21.8735, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(23.6658, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(21.5907, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(23.3825, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(21.3081, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(23.0995, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(21.0255, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(22.8164, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(20.7412, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(22.5315, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(20.4571, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(22.2469, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(20.1733, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(21.9625, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(19.8897, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(21.6783, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(19.6066, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(21.3945, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(19.3238, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(21.1110, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(19.0414, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(20.8279, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:   4%|▎         | 36/1000 [00:00<00:09, 106.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18.7595, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(20.5452, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(18.4781, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(20.2630, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(18.1971, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(19.9812, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(17.9166, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(19.6998, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(17.6367, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(19.4190, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(17.3574, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(19.1388, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(17.0825, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(18.8629, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(16.8141, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(18.5934, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(16.5467, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(18.3250, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(16.2805, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(18.0576, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(16.0012, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(17.7772, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(15.7098, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(17.4846, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(15.4178, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(17.1915, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(15.1255, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(16.8979, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(14.8329, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(16.6041, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(14.5403, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(16.3102, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(14.2479, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(16.0164, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(13.9557, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(15.7229, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(13.6640, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(15.4298, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(13.3727, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(15.1371, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(13.0822, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(14.8451, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:   6%|▌         | 58/1000 [00:00<00:09, 102.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(12.7924, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(14.5539, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(12.5565, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(14.3164, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(12.3409, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(14.0992, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(12.1297, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(13.8864, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(11.9226, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(13.6775, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(11.7192, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(13.4724, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(11.5193, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(13.2705, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(11.3225, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(13.0718, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(11.1286, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(12.8760, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(10.9374, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(12.6827, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(10.7487, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(12.4920, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(10.5624, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(12.3035, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(10.3782, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(12.1172, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(10.1963, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(11.9331, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(10.0163, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(11.7508, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(9.8383, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(11.5705, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(9.6621, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(11.3921, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(9.4879, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(11.2155, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(9.3155, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(11.0406, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(9.1449, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(10.8676, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:   8%|▊         | 81/1000 [00:00<00:08, 106.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(8.9762, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(10.6964, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(8.8093, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(10.5271, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(8.6444, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(10.3597, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(8.4815, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(10.1942, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(8.3207, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(10.0308, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(8.1620, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(9.8695, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(8.0055, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(9.7104, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(7.8514, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(9.5536, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(7.6999, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(9.3993, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(7.5509, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(9.2476, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(7.4047, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(9.0986, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(7.2614, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(8.9525, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(7.1211, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(8.8095, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(6.9841, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(8.6696, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(6.8504, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(8.5331, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(6.7203, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(8.4001, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(6.5938, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(8.2707, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(6.4712, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(8.1450, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(6.3524, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(8.0233, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(6.2377, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(7.9056, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(6.1272, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(7.7920, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(6.0208, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(7.6826, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  10%|█         | 105/1000 [00:00<00:08, 109.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.9188, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(7.5774, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(5.8210, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(7.4765, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(5.7275, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(7.3799, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(5.6384, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(7.2876, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(5.5536, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(7.1996, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(5.4729, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(7.1157, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(5.3965, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(7.0360, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(5.3242, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.9604, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(5.2558, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.8887, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(5.1914, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.8209, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(5.1307, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.7568, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(5.0737, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.6964, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(5.0202, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.6394, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.9701, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.5859, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.9233, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.5356, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.8795, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.4883, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.8388, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.4441, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.8010, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.4026, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.7658, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.3639, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.7333, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.3277, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.7032, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.2940, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.6754, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.2626, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.6499, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.2334, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  13%|█▎        | 128/1000 [00:01<00:07, 109.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.6264, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.2062, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.6050, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.1810, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.5853, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.1576, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.5674, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.1360, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.5512, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.1159, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.5364, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.0974, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.5231, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.0803, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.5111, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.0644, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.5003, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.0498, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4906, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.0363, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4820, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.0239, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4744, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.0124, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4676, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(6.0017, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4616, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.9919, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4564, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.9827, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4518, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.9742, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4478, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.9663, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4443, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.9590, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4413, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.9521, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4388, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.9456, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4366, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.9395, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4347, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.9337, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  15%|█▌        | 152/1000 [00:01<00:07, 111.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1  tensor(4.4332, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.9282, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4318, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.9230, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4308, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.9180, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4299, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.9132, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4291, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.9086, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4286, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.9041, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4281, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8997, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4277, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8955, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4275, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8913, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4272, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8872, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4271, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8832, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8792, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8753, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8714, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4268, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8675, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4268, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8637, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4268, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8599, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4268, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8561, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4268, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8523, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8486, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8448, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8411, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8374, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Explain node 123:  16%|█▋        | 164/1000 [00:01<00:07, 110.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8337, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8300, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8264, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8227, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8191, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8154, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8118, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8083, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8047, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.8011, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7976, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7941, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7906, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7871, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7837, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4268, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7802, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4268, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7768, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4268, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7734, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4268, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7701, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4268, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7667, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4268, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7634, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4268, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7601, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4268, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7569, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  19%|█▉        | 188/1000 [00:01<00:07, 113.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4268, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7536, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4268, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7504, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4268, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7472, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4268, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7440, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4268, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7408, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7377, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7346, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7315, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7284, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7254, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7224, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7194, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7164, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7134, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7105, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7076, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7047, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4269, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.7018, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6990, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6961, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6933, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6905, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6878, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6850, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  21%|██▏       | 213/1000 [00:01<00:07, 111.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6823, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6796, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6769, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6742, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6716, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6689, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6663, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6637, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6612, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6586, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6561, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6536, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6511, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6486, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6461, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6437, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6413, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6389, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6365, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6341, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6317, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6294, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  24%|██▎       | 237/1000 [00:02<00:06, 110.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6271, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6248, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6225, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6202, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6180, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6157, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6135, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6113, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6091, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6070, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6048, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6027, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.6006, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5985, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5964, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5943, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5922, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5902, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5882, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5862, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5842, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  26%|██▌       | 261/1000 [00:02<00:06, 111.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.5822, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5802, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5783, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5763, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5744, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5725, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5706, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5687, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5669, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5650, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5632, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5614, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5595, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5577, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5560, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5542, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5524, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5507, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5490, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5472, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5455, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5438, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5422, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5405, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  28%|██▊       | 285/1000 [00:02<00:06, 112.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5388, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5372, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5356, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5339, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5323, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5307, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5292, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5276, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5260, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5245, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5229, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5214, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5199, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5184, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5169, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5154, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5139, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5125, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5110, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5096, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5081, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5067, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  31%|███       | 309/1000 [00:02<00:06, 112.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 2  tensor(5.5053, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5039, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5025, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.5011, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4998, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4984, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4971, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4957, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4944, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4931, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4917, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4904, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4891, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4879, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4866, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4853, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4841, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4828, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4816, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4803, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4791, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4779, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4767, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  33%|███▎      | 333/1000 [00:03<00:05, 114.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4755, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4743, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4731, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4719, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4708, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4696, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4685, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4673, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4662, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4651, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4639, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4628, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4617, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4606, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4595, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4585, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4574, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4563, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4553, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4542, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4532, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4521, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4511, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  36%|███▌      | 357/1000 [00:03<00:05, 113.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 2  tensor(5.4501, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4490, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4480, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4470, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4460, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4450, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4441, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4431, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4421, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4411, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4402, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4392, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4383, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4373, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4364, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4355, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4346, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4336, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4327, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4318, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4309, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4300, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4291, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Explain node 123:  37%|███▋      | 369/1000 [00:03<00:06, 104.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss 2  tensor(5.4283, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4274, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4265, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4257, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4248, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4239, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4231, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4222, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4214, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4206, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4198, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4189, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4181, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4173, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4165, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4157, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4149, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4141, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  39%|███▉      | 391/1000 [00:03<00:06, 96.52it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4133, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4125, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4118, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4110, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4102, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4095, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4087, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4079, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4072, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4064, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4057, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4050, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4042, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4035, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4028, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4021, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4014, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.4007, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  41%|████      | 411/1000 [00:03<00:06, 94.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3999, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3992, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3986, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3979, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3972, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3965, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3958, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3951, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3945, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3938, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3931, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3925, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3918, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3912, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3905, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3899, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3892, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3886, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3880, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  43%|████▎     | 434/1000 [00:04<00:05, 100.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3873, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3867, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3861, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3855, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3848, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3842, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3836, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3830, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3824, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3818, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3812, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3806, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3800, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3795, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3789, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3783, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3777, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3771, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3766, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3760, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3754, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3749, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Explain node 123:  44%|████▍     | 445/1000 [00:04<00:05, 98.73it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3743, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3738, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3732, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3727, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3721, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3716, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3711, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3705, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3700, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3695, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3689, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3684, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3679, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3674, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3669, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3664, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3658, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3653, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  46%|████▋     | 465/1000 [00:04<00:05, 90.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3648, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3643, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3638, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3633, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3628, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3624, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3619, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3614, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3609, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3604, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3599, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3595, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3590, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3585, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3581, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3576, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3571, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  48%|████▊     | 485/1000 [00:04<00:05, 90.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 2  tensor(5.3567, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3562, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3558, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3553, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3549, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3544, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3540, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3535, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3531, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3526, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3522, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3518, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3513, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3509, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3505, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3500, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3496, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3492, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  51%|█████     | 507/1000 [00:04<00:05, 96.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss 2  tensor(5.3488, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3484, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3479, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3475, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3471, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3467, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3463, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3459, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3455, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3451, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3447, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3443, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3439, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3435, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3431, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3427, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3423, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3420, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3416, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3412, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3408, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Explain node 123:  52%|█████▏    | 517/1000 [00:04<00:05, 93.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3404, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3401, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3397, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3393, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3390, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3386, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3382, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3378, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3375, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3371, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3368, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3364, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3361, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3357, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3353, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3350, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3346, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3343, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  54%|█████▍    | 539/1000 [00:05<00:04, 97.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3339, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3336, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3333, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3329, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3326, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3322, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3319, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3316, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3312, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3309, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3306, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3302, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3299, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3296, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3293, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3289, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3286, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3283, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3280, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3277, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3274, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  56%|█████▌    | 559/1000 [00:05<00:04, 95.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3270, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3267, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3264, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3261, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3258, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3255, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3252, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3249, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3246, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3243, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3240, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3237, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3234, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3231, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3228, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3225, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3222, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3219, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3216, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  58%|█████▊    | 579/1000 [00:05<00:04, 92.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3213, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3211, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3208, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3205, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3202, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3199, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3196, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3194, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3191, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3188, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3185, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3183, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3180, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3177, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3174, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3172, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3169, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3166, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3164, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  60%|██████    | 600/1000 [00:05<00:04, 95.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3161, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3158, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3156, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3153, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3151, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3148, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3145, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3143, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3140, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3138, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3135, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3133, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3130, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3128, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3125, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3123, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3120, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3118, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3115, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3113, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  62%|██████▏   | 620/1000 [00:06<00:04, 91.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3110, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3108, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3106, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3103, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3101, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3098, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3096, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3094, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3091, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3089, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3087, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3084, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3082, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3080, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3077, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3075, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3073, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  64%|██████▍   | 642/1000 [00:06<00:03, 97.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3071, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3068, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3066, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3064, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3062, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3059, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3057, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3055, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3053, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3051, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3048, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3046, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3044, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3042, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3040, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3038, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3036, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3033, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3031, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3029, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3027, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Explain node 123:  65%|██████▌   | 652/1000 [00:06<00:03, 94.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3025, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3023, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3021, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3019, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3017, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3015, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3013, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3011, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3009, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3007, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3005, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3003, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.3001, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2999, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2997, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2995, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2993, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2991, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  67%|██████▋   | 672/1000 [00:06<00:03, 92.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 2  tensor(5.2989, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2987, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2985, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2983, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2981, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2979, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2977, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2976, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2974, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2972, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2970, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2968, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2966, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2964, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2963, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2961, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2959, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2957, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2955, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  69%|██████▉   | 694/1000 [00:06<00:03, 98.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2953, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2952, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2950, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2948, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2946, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2945, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2943, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2941, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2939, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2937, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2936, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2934, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2932, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2931, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2929, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2927, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2925, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2924, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2922, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2920, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2919, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2917, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  72%|███████▏  | 715/1000 [00:07<00:03, 93.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2915, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2914, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2912, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2910, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2909, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2907, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2906, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2904, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2902, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2901, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2899, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2897, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2896, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2894, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2893, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2891, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  74%|███████▎  | 736/1000 [00:07<00:02, 93.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2890, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2888, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2886, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2885, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2883, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2882, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2880, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2879, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2877, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2876, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2874, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2873, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2871, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2870, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2868, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2867, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2865, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2864, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2862, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2861, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  76%|███████▌  | 757/1000 [00:07<00:02, 93.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2859, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2858, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2856, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2855, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2854, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2852, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2851, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2849, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2848, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2846, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2845, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2844, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2842, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2841, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2839, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2838, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2837, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2835, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2834, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Explain node 123:  77%|███████▋  | 767/1000 [00:07<00:02, 92.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2833, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2831, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2830, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2828, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2827, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2826, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2824, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2823, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2822, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2820, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2819, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2818, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2816, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2815, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2814, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2813, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2811, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2810, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2809, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2807, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  79%|███████▉  | 791/1000 [00:07<00:01, 104.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2806, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2805, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2804, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2802, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2801, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2800, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2799, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2797, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2796, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2795, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2794, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2792, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2791, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2790, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2789, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2787, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2786, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2785, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2784, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2783, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2781, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2780, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2779, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2778, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  82%|████████▏ | 815/1000 [00:08<00:01, 109.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2777, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2775, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2774, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2773, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2772, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2771, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2770, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2768, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2767, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2766, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2765, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2764, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2763, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2762, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2761, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2759, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2758, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2757, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2756, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2755, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2754, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2753, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  84%|████████▍ | 838/1000 [00:08<00:01, 101.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2752, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2751, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2749, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2748, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2747, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2746, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2745, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2744, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2743, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2742, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2741, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2740, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2739, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2738, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2737, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2735, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2734, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2733, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2732, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  86%|████████▌ | 862/1000 [00:08<00:01, 108.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2731, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2730, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2729, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2728, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2727, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2726, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2725, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2724, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2723, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2722, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2721, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2720, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2719, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2718, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2717, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2716, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2715, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2714, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2713, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2712, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2711, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2710, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2709, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2708, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  89%|████████▊ | 886/1000 [00:08<00:01, 112.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2707, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2706, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2705, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2704, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2703, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2703, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2702, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2701, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2700, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2699, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2698, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2697, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2696, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2695, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2694, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2693, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2692, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2691, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2690, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2690, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2689, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2688, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2687, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2686, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  91%|█████████ | 911/1000 [00:08<00:00, 114.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2685, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2684, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2683, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2682, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2681, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2681, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2680, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2679, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2678, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2677, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2676, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2675, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2674, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2674, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2673, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2672, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2671, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2670, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2669, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2668, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2668, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2667, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Explain node 123:  92%|█████████▏| 923/1000 [00:09<00:00, 102.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 2  tensor(5.2666, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2665, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2664, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2663, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2663, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2662, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2661, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2660, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2659, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2658, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2658, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2657, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2656, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2655, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2654, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2654, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2653, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  94%|█████████▍| 945/1000 [00:09<00:00, 99.67it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2652, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2651, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2650, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2650, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2649, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2648, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2647, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2646, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2646, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2645, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2644, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2643, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2642, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2642, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2641, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2640, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2639, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2639, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2638, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2637, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2636, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2636, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  97%|█████████▋| 968/1000 [00:09<00:00, 102.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2635, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2634, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2633, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2633, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2632, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2631, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2630, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2630, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2629, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2628, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2627, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2627, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2626, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2625, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2624, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2624, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2623, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2622, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2622, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2621, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2620, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123:  99%|█████████▉| 989/1000 [00:09<00:00, 93.78it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2619, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2619, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2618, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2617, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2617, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2616, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2615, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2614, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2614, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2613, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2612, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2612, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2611, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2610, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2610, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2609, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2608, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 123: 100%|██████████| 1000/1000 [00:09<00:00, 101.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2608, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2607, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2606, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2606, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2605, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2604, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2604, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2603, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2602, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2602, grad_fn=<AddBackward0>)\n",
      "Output  torch.Size([47, 4])\n",
      "Node_idx  tensor([46])\n",
      "log_logits  torch.Size([47, 4])\n",
      "pred label  torch.Size([47])\n",
      "Loss 1  tensor(4.4270, grad_fn=<NegBackward>)\n",
      "Loss 2  tensor(5.2601, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "node_idx = 123\n",
    "# convert to edge format\n",
    "edges = data['edges'].t().contiguous()\n",
    "\n",
    "explainer = GNNExplainer(model, epochs=1000, return_type='log_prob', log=True)\n",
    "node_feat_mask, edge_mask = explainer.explain_node(node_idx, data['x'], data['edges'])\n",
    "\n",
    "ax, G = explainer.visualize_subgraph(node_idx, data['edges'], edge_mask, y=data['y'], threshold=0.8)\n",
    "plt.title(f\"GNNExplainer explanation for Node {node_idx}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "stunning-empire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9875666074600356\n",
      "0.9635036496350365\n"
     ]
    }
   ],
   "source": [
    "x = data[\"x\"]\n",
    "edges = data[\"edges\"]\n",
    "y = data[\"y\"]\n",
    "train_mask = data[\"train_mask\"]\n",
    "test_mask = data[\"test_mask\"]\n",
    "print(test(model, x, y, edges, train_mask))\n",
    "print(test(model, x, y, edges, test_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-reminder",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_num, key in enumerate(activation_list):\n",
    "    print(key)\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    print(activation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-globe",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction\n",
    "\n",
    "### TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-tunisia",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TSNE conversion\n",
    "tsne_models = []\n",
    "tsne_data = []\n",
    "\n",
    "for layer_num, key in enumerate(activation_list):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    tsne_model = TSNE(n_components=2)\n",
    "    d = tsne_model.fit_transform(activation)\n",
    "    plot_activation_space(d, labels, \"t-SNE reduced\", layer_num, paths['TSNE'], \"(coloured by labels)\")\n",
    "    \n",
    "    tsne_models.append(tsne_model)\n",
    "    tsne_data.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-consolidation",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-microphone",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# PCA conversion\n",
    "pca_models = []\n",
    "pca_data = []\n",
    "for layer_num, key in enumerate(activation_list):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    pca_model = PCA(n_components=2)\n",
    "    d = pca_model.fit_transform(activation)\n",
    "    plot_activation_space(d, labels, \"PCA reduced\", layer_num, paths['PCA'], \"(coloured by labels)\")\n",
    "\n",
    "    pca_models.append(pca_model)\n",
    "    pca_data.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-national",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-warrior",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# UMAP conversion\n",
    "umap_models = []\n",
    "umap_data = []\n",
    "for layer_num, key in enumerate(activation_list):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    umap_model = umap.UMAP(n_components=2)\n",
    "    d = umap_model.fit_transform(activation)\n",
    "    plot_activation_space(d, labels, \"UMAP reduced\", layer_num, paths['UMAP'], \"(coloured by labels)\")\n",
    "\n",
    "    umap_models.append(umap_model)\n",
    "    umap_data.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-catch",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-brooks",
   "metadata": {},
   "source": [
    "### KMeans\n",
    "\n",
    "##### RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-anthropology",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_nodes_view = 5\n",
    "num_expansions = 2\n",
    "edges = data['edge_list'].numpy()\n",
    "\n",
    "raw_kmeans_sample_feat = []\n",
    "raw_kmeans_sample_graphs = []\n",
    "raw_kmeans_models = []\n",
    "for layer_num, key in enumerate(activation_list):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    kmeans_model = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans_model = kmeans_model.fit(activation)\n",
    "    pred_labels = kmeans_model.predict(activation)\n",
    "        \n",
    "    plot_clusters(tsne_data[layer_num], pred_labels, \"k-Means\", k, layer_num, paths['KMeans'], \"Raw\", \"_TSNE\", \"(t-SNE reduced)\")\n",
    "    plot_clusters(pca_data[layer_num], pred_labels, \"k-Means\", k, layer_num, paths['KMeans'], \"Raw\", \"_PCA\", \"(PCA reduced)\")\n",
    "    plot_clusters(umap_data[layer_num], pred_labels, \"k-Means\", k, layer_num, paths['KMeans'], \"Raw\", \"_UMAP\", \"(UMAP reduced)\")\n",
    "    sample_graphs, sample_feat = plot_samples(kmeans_model, activation, data[\"y\"], layer_num, k, \"Kmeans\", \"raw\", num_nodes_view, edges, num_expansions, paths['KMeans'])\n",
    "\n",
    "    raw_kmeans_sample_graphs.append(sample_graphs)\n",
    "    raw_kmeans_sample_feat.append(sample_feat)\n",
    "    raw_kmeans_models.append(kmeans_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-afghanistan",
   "metadata": {},
   "source": [
    "##### TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-mistress",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tsne_kmeans_sample_graphs = []\n",
    "tsne_kmeans_sample_feat = []\n",
    "tsne_kmeans_models = []\n",
    "for layer_num, item in enumerate(tsne_data):\n",
    "    kmeans_model = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans_model = kmeans_model.fit(item)\n",
    "    pred_labels = kmeans_model.predict(item)\n",
    "\n",
    "    plot_clusters(item, pred_labels, \"k-Means\", k, layer_num, paths['KMeans'], \"t-SNE reduced\")\n",
    "    sample_graphs, sample_feat = plot_samples(kmeans_model, item, data[\"y\"], layer_num, k, \"k-Means\", \"t-SNE reduced\", num_nodes_view, edges, num_expansions, paths['KMeans'])\n",
    "\n",
    "    tsne_kmeans_sample_graphs.append(sample_graphs)\n",
    "    tsne_kmeans_sample_feat.append(sample_feat)\n",
    "    tsne_kmeans_models.append(kmeans_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-juvenile",
   "metadata": {},
   "source": [
    "##### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-settle",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pca_kmeans_sample_graphs = []\n",
    "pca_kmeans_sample_feat = []\n",
    "pca_kmeans_models = []\n",
    "\n",
    "for layer_num, item in enumerate(pca_data):\n",
    "    kmeans_model = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans_model = kmeans_model.fit(item)\n",
    "    pred_labels = kmeans_model.predict(item)\n",
    "\n",
    "    plot_clusters(item, pred_labels, \"k-Means\", k, layer_num, paths['KMeans'], \"PCA reduced\")\n",
    "    sample_graphs, sample_feat = plot_samples(kmeans_model, item, data[\"y\"], layer_num, k, \"k-Means\", \"PCA reduced\", num_nodes_view, edges, num_expansions, paths['KMeans'])\n",
    "\n",
    "    pca_kmeans_sample_graphs.append(sample_graphs)\n",
    "    pca_kmeans_sample_feat.append(sample_feat)\n",
    "    pca_kmeans_models.append(kmeans_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-terror",
   "metadata": {},
   "source": [
    "##### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-garden",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "umap_kmeans_sample_graphs = []\n",
    "umap_kmeans_sample_feat = []\n",
    "umap_kmeans_models = []\n",
    "for layer_num, item in enumerate(umap_data):\n",
    "    kmeans_model = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans_model = kmeans_model.fit(item)\n",
    "    pred_labels = kmeans_model.predict(item)\n",
    "\n",
    "    plot_clusters(item, pred_labels, \"k-Means\", k, layer_num, paths['KMeans'], \"UMAP reduced\")\n",
    "    sample_graphs, sample_feat = plot_samples(kmeans_model, item, data[\"y\"], layer_num, k, \"k-Means\", \"UMAP reduced\", num_nodes_view, edges, num_expansions, paths['KMeans'])\n",
    "\n",
    "    umap_kmeans_sample_graphs.append(sample_graphs)\n",
    "    umap_kmeans_sample_feat.append(sample_feat)\n",
    "    umap_kmeans_models.append(kmeans_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-moses",
   "metadata": {},
   "source": [
    "#### Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-idaho",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ba_heuristics = BA_Shapes_Heuristics()\n",
    "\n",
    "# for layer_num, sample in enumerate(raw_sample_graphs):\n",
    "#     plot_heuristics_table(ba_heuristics, sample, layer_num, \"k-Means\", \"raw\", paths['KMeans'])\n",
    "\n",
    "# for layer_num, sample in enumerate(tsne_sample_graphs):\n",
    "#     plot_heuristics_table(ba_heuristics, sample, layer_num, \"k-Means\", \"t-SNE reduced\", paths['KMeans'])\n",
    "\n",
    "# for layer_num, sample in enumerate(pca_sample_graphs):\n",
    "#     plot_heuristics_table(ba_heuristics, sample, layer_num, \"k-Means\", \"PCA reduced\", paths['KMeans'])\n",
    "\n",
    "# # for layer_num, sample in enumerate(umap_sample_graphs):\n",
    "#     plot_heuristics_table(ba_heuristics, sample, layer_num, \"k-Means\", \"UMAP reduced\", paths['KMeans'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-start",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-conducting",
   "metadata": {},
   "source": [
    "##### Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-memphis",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for layer_num, key in enumerate(activation_list):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    plot_dendrogram(activation, \"raw\", layer_num, paths['Ward'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-explanation",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "raw_n_clusters = [4, 6, 23, 14, 30]\n",
    "\n",
    "raw_hc_sample_graphs = []\n",
    "raw_hc_sample_feat = []\n",
    "raw_hc_models = []\n",
    "for layer_num, (key, n) in enumerate(zip(activation_list, raw_n_clusters)):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    hc = AgglomerativeClustering(n_clusters=n, affinity='euclidean', linkage='ward')\n",
    "    pred_labels = hc.fit_predict(activation)\n",
    "\n",
    "    d = (activation, pred_labels)\n",
    "    plot_clusters(tsne_data[layer_num], pred_labels, \"HC-Ward\", n, layer_num, paths['Ward'], \"raw\", \"_TSNE\", \"(t-SNE reduced)\")\n",
    "    plot_clusters(pca_data[layer_num], pred_labels, \"HC-Ward\", n, layer_num, paths['Ward'], \"raw\", \"_PCA\", \"(PCA reduced)\")\n",
    "    plot_clusters(pca_data[layer_num], pred_labels, \"HC-Ward\", n, layer_num, paths['Ward'], \"raw\", \"_UMAP\", \"(UMAP reduced)\")\n",
    "    sample_graphs, sample_feat = plot_samples(hc, d, data[\"y\"], layer_num, n, \"HC\", \"raw\", num_nodes_view, edges, num_expansions, paths['Ward'])\n",
    "\n",
    "    raw_hc_sample_graphs.append(sample_graphs)\n",
    "    raw_hc_sample_feat.append(sample_feat)\n",
    "    raw_hc_models.append(hc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-terrorism",
   "metadata": {},
   "source": [
    "##### TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-silver",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for layer_num, item in enumerate(tsne_data):\n",
    "    plot_dendrogram(item, \"t-SNE\", layer_num, paths['Ward'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-portrait",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tsne_n_clusters = [5, 4, 30, 13, 7]\n",
    "\n",
    "tsne_hc_sample_graphs = []\n",
    "tsne_hc_sample_feat = []\n",
    "tsne_hc_models = []\n",
    "for layer_num, (item, n) in enumerate(zip(tsne_data, tsne_n_clusters)):\n",
    "    hc = AgglomerativeClustering(n_clusters=n, affinity='euclidean', linkage='ward')\n",
    "    pred_labels = hc.fit_predict(item)\n",
    "\n",
    "    d = (item, pred_labels)\n",
    "    plot_clusters(item, pred_labels, \"HC\", n, layer_num, paths['Ward'], \"t-SNE\")\n",
    "    sample_graphs, sample_feat = plot_samples(hc, d, data[\"y\"], layer_num, n, \"HC\", \"t-SNE reduced\", num_nodes_view, edges, num_expansions, paths['Ward'])\n",
    "\n",
    "    tsne_hc_sample_graphs.append(sample_graphs)\n",
    "    tsne_hc_sample_feat.append(sample_feat)\n",
    "    tsne_hc_models.append(hc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-indication",
   "metadata": {},
   "source": [
    "##### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-comparative",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for layer_num, item in enumerate(pca_data):\n",
    "    plot_dendrogram(item, \"PCA\", layer_num, paths['Ward'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-asthma",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pca_n_clusters = [24, 7, 3, 5, 8]\n",
    "\n",
    "pca_hc_sample_graphs = []\n",
    "pca_hc_sample_feat = []\n",
    "pca_hc_models = []\n",
    "for layer_num, (item, n) in enumerate(zip(pca_data, pca_n_clusters)):\n",
    "    hc = AgglomerativeClustering(n_clusters=n, affinity='euclidean', linkage='ward')\n",
    "    pred_labels = hc.fit_predict(item)\n",
    "\n",
    "    d = (item, pred_labels)\n",
    "    plot_clusters(item, pred_labels, \"HC\", n, layer_num, paths['HC'], \"PCA\")\n",
    "    sample_graphs, sample_feat = plot_samples(hc, d, data[\"y\"], layer_num, n, \"HC\", \"PCA reduced\", num_nodes_view, edges, num_expansions, paths['HC'])\n",
    "\n",
    "    pca_hc_sample_graphs.append(sample_graphs)\n",
    "    pca_hc_sample_feat.append(sample_feat)\n",
    "    pca_hc_models.append(hc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-sweden",
   "metadata": {},
   "source": [
    "##### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-klein",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for layer_num, item in enumerate(umap_data):\n",
    "    plot_dendrogram(item, \"UMAP\", layer_num, paths['Ward'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-internship",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "umap_n_clusters = [10, 24, 30, 30, 30]\n",
    "\n",
    "umap_hc_sample_graphs = []\n",
    "umap_hc_sample_feat = []\n",
    "umap_hc_models = []\n",
    "for layer_num, (item, n) in enumerate(zip(umap_data, umap_n_clusters)):\n",
    "    hc = AgglomerativeClustering(n_clusters=n, affinity='euclidean', linkage='ward')\n",
    "    pred_labels = hc.fit_predict(item)\n",
    "\n",
    "    d = (item, pred_labels)\n",
    "    plot_clusters(item, pred_labels, \"HC\", n, layer_num, paths['Ward'], \"UMAP\")\n",
    "    sample_graphs, sample_feat = plot_samples(hc, d, data[\"y\"], layer_num, n, \"HC\", \"UMAP reduced\", num_nodes_view, edges, num_expansions, paths['Ward'])\n",
    "\n",
    "    umap_hc_sample_graphs.append(sample_graphs)\n",
    "    umap_hc_sample_feat.append(sample_feat)\n",
    "    umap_hc_models.append(hc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-facing",
   "metadata": {},
   "source": [
    "#### Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-request",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for layer_num, sample in enumerate(raw_sample_graphs):\n",
    "#     plot_heuristics_table(ba_heuristics, sample, layer_num, \"HC-Ward\", \"raw\", paths['Ward'])\n",
    "\n",
    "# for layer_num, sample in enumerate(tsne_sample_graphs):\n",
    "#     plot_heuristics_table(ba_heuristics, sample, layer_num, \"HC-Ward\", \"t-SNE reduced\", paths['Ward'])\n",
    "\n",
    "# for layer_num, sample in enumerate(pca_sample_graphs):\n",
    "#     plot_heuristics_table(ba_heuristics, sample, layer_num, \"HC-Ward\", \"PCA reduced\", paths['Ward'])\n",
    "\n",
    "# for layer_num, sample in enumerate(umap_sample_graphs):\n",
    "#     plot_heuristics_table(ba_heuristics, sample, layer_num, \"HC-Ward\", \"UMAP reduced\", paths['Ward'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-sally",
   "metadata": {},
   "source": [
    "### DBSCAN\n",
    "\n",
    "##### Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-decade",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# num_nodes_view = 5\n",
    "# num_expansions = 2\n",
    "# edges = data['edge_list'].numpy()\n",
    "\n",
    "raw_dbscan_sample_feats = []\n",
    "raw_dbscan_sample_graphs = []\n",
    "raw_dbscan_models = []\n",
    "raw_dbscan_ds = []\n",
    "\n",
    "esp = 0.5\n",
    "min_samples = 5\n",
    "\n",
    "for layer_num, key in enumerate(activation_list):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    dbscan_model = DBSCAN(eps=esp, min_samples=min_samples)\n",
    "    dbscan_model = dbscan_model.fit(activation)\n",
    "    pred_labels = dbscan_model.fit_predict(activation)\n",
    "\n",
    "    num_cluster = len(np.unique(pred_labels))\n",
    "    d = (activation, pred_labels)\n",
    "    raw_dbscan_ds.append(d)\n",
    "\n",
    "    plot_clusters(tsne_data[layer_num], pred_labels, \"DBSCAN\", num_cluster, layer_num, paths['DBSCAN'], \"Raw\", \"_TSNE\", \"(TSNE Reduced)\")\n",
    "    plot_clusters(pca_data[layer_num], pred_labels, \"DBSCAN\", num_cluster, layer_num, paths['DBSCAN'], \"Raw\", \"_PCA\", \"(PCA Reduced)\")\n",
    "    plot_clusters(pca_data[layer_num], pred_labels, \"DBSCAN\", num_cluster, layer_num, paths['DBSCAN'], \"Raw\", \"_UMAP\", \"(UMAP Reduced)\")\n",
    "    sample_graphs, sample_feat = plot_samples(dbscan_model, d, data[\"y\"], layer_num, num_cluster, \"DBSCAN\", \"raw\", num_nodes_view, edges, num_expansions, paths['DBSCAN'])\n",
    "\n",
    "    raw_dbscan_sample_graphs.append(sample_graphs)\n",
    "    raw_dbscan_sample_feats.append(sample_feat)\n",
    "    raw_dbscan_models.append((dbscan_model, num_cluster))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-kenya",
   "metadata": {},
   "source": [
    "##### TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-senior",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tsne_dbscan_sample_graphs = []\n",
    "tsne_dbscan_sample_feats = []\n",
    "tsne_dbscan_models = []\n",
    "tsne_dbscan_ds = []\n",
    "\n",
    "for layer_num, item in enumerate(tsne_data):\n",
    "    dbscan_model = DBSCAN(eps=esp, min_samples=min_samples)\n",
    "    dbscan_model = dbscan_model.fit(item)\n",
    "    pred_labels = dbscan_model.fit_predict(item)\n",
    "\n",
    "    num_cluster = len(np.unique(pred_labels))\n",
    "    d = (item, pred_labels)\n",
    "    tsne_dbscan_ds.append(d)\n",
    "\n",
    "    plot_clusters(item, pred_labels, \"DBSCAN\", num_cluster, layer_num, paths['DBSCAN'], \"t-SNE\")\n",
    "    sample_graphs, sample_feat = plot_samples(dbscan_model, d, data[\"y\"], layer_num, num_cluster, \"DBSCAN\", \"t-SNE reduced\", num_nodes_view, edges, num_expansions, paths['DBSCAN'])\n",
    "\n",
    "    tsne_dbscan_sample_graphs.append(sample_graphs)\n",
    "    tsne_dbscan_sample_feats.append(sample_feat)\n",
    "    tsne_dbscan_models.append((dbscan_model, num_cluster))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-mapping",
   "metadata": {},
   "source": [
    "##### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-persian",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pca_dbscan_sample_graphs = []\n",
    "pca_dbscan_sample_feats = []\n",
    "pca_dbscan_models = []\n",
    "pca_dbscan_ds = []\n",
    "\n",
    "for layer_num, item in enumerate(pca_data):\n",
    "    dbscan_model = DBSCAN(eps=esp, min_samples=min_samples)\n",
    "    dbscan_model = dbscan_model.fit(item)\n",
    "    pred_labels = dbscan_model.fit_predict(item)\n",
    "\n",
    "    num_cluster = len(np.unique(pred_labels))\n",
    "    d = (item, pred_labels)\n",
    "    pca_dbscan_ds.append(d)\n",
    "\n",
    "    plot_clusters(item, pred_labels, \"DBSCAN\", num_cluster, layer_num, paths['DBSCAN'], \"PCA\")\n",
    "    sample_graphs, sample_feat = plot_samples(dbscan_model, d, data[\"y\"], layer_num, num_cluster, \"DBSCAN\", \"PCA reduced\", num_nodes_view, edges, num_expansions, paths['DBSCAN'])\n",
    "\n",
    "    pca_dbscan_sample_graphs.append(sample_graphs)\n",
    "    pca_dbscan_sample_feats.append(sample_feat)\n",
    "    pca_dbscan_models.append((dbscan_model, num_cluster))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-williams",
   "metadata": {},
   "source": [
    "##### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-quality",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "umap_dbscan_sample_graphs = []\n",
    "umap_dbscan_sample_feats = []\n",
    "umap_dbscan_models = []\n",
    "umap_dbscan_ds = []\n",
    "\n",
    "for layer_num, item in enumerate(umap_data):\n",
    "    dbscan_model = DBSCAN(eps=esp, min_samples=min_samples)\n",
    "    dbscan_model = dbscan_model.fit(item)\n",
    "    pred_labels = dbscan_model.fit_predict(item)\n",
    "\n",
    "    num_cluster = len(np.unique(pred_labels))\n",
    "    d = (item, pred_labels)\n",
    "    umap_dbscan_ds.append(d)\n",
    "\n",
    "    plot_clusters(item, pred_labels, \"DBSCAN\", num_cluster, layer_num, paths['DBSCAN'], \"UMAP\")\n",
    "    sample_graphs, sample_feat = plot_samples(dbscan_model, d, data[\"y\"], layer_num, num_cluster, \"DBSCAN\", \"UMAP reduced\", num_nodes_view, edges, num_expansions, paths['DBSCAN'])\n",
    "\n",
    "    umap_dbscan_sample_graphs.append(sample_graphs)\n",
    "    umap_dbscan_sample_feats.append(sample_feat)\n",
    "    umap_dbscan_models.append((dbscan_model, num_cluster))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-slovakia",
   "metadata": {},
   "source": [
    "#### Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-honduras",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for layer_num, sample in enumerate(raw_sample_graphs):\n",
    "#     plot_heuristics_table(ba_heuristics, sample, layer_num, \"DBSCAN\", \"raw\", paths['DBSCAN'])\n",
    "\n",
    "# for layer_num, sample in enumerate(tsne_sample_graphs):\n",
    "#     plot_heuristics_table(ba_heuristics, sample, layer_num, \"DBSCAN\", \"t-SNE reduced\", paths['DBSCAN'])\n",
    "\n",
    "# for layer_num, sample in enumerate(pca_sample_graphs):\n",
    "#     plot_heuristics_table(ba_heuristics, sample, layer_num, \"DBSCAN\", \"PCA reduced\", paths['DBSCAN'])\n",
    "\n",
    "# for layer_num, sample in enumerate(umap_sample_graphs):\n",
    "#     plot_heuristics_table(ba_heuristics, sample, layer_num, \"DBSCAN\", \"UMAP reduced\", paths['DBSCAN'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-charity",
   "metadata": {},
   "source": [
    "# Activation to Concept to Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-grave",
   "metadata": {},
   "source": [
    "### Using KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-license",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classifier_str = \"decision_tree\"\n",
    "\n",
    "completeness_scores = []\n",
    "\n",
    "for i, key in enumerate(activation_list):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    activation_cls = ActivationClassifier(activation, raw_kmeans_models[i], classifier_str, data[\"x\"], data[\"y\"], data[\"train_mask\"], data[\"test_mask\"])\n",
    "    \n",
    "    d = [\"Raw\", str(i), str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(paths['KMeans'], i, k, \"raw\")\n",
    "    \n",
    "for i, item in enumerate(tsne_data):\n",
    "    activation_cls = ActivationClassifier(item, tsne_kmeans_models[i], classifier_str, data[\"x\"], data[\"y\"], data[\"train_mask\"], data[\"test_mask\"])\n",
    "\n",
    "    d = [\"t-SNE reduced\", str(i), str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(paths['KMeans'], i, k, \"t-SNE\")\n",
    "\n",
    "for i, item in enumerate(pca_data):\n",
    "    activation_cls = ActivationClassifier(item, pca_kmeans_models[i], classifier_str, data[\"x\"], data[\"y\"], data[\"train_mask\"], data[\"test_mask\"])\n",
    "\n",
    "    d = [\"PCA reduced\", str(i), str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(paths['KMeans'], i, k, \"PCA\")\n",
    "\n",
    "for i, item in enumerate(umap_data):\n",
    "    activation_cls = ActivationClassifier(item, umap_kmeans_models[i], classifier_str, data[\"x\"], data[\"y\"], data[\"train_mask\"], data[\"test_mask\"])\n",
    "\n",
    "    d = [\"UMAP reduced\", str(i), str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(paths['KMeans'], i, k, \"UMAP\")\n",
    "\n",
    "plot_completeness_table(\"k-Means\", \"Decision Tree\", completeness_scores, paths['KMeans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-booth",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classifier_str = \"logistic_regression\"\n",
    "\n",
    "completeness_scores = []\n",
    "\n",
    "for i, key in enumerate(activation_list):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    activation_cls = ActivationClassifier(activation, raw_kmeans_models[i], classifier_str, data[\"x\"], data[\"y\"], data[\"train_mask\"], data[\"test_mask\"])\n",
    "    \n",
    "    d = [\"Raw\", str(i), str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(paths['KMeans'], i, k, \"raw\")\n",
    "    \n",
    "for i, item in enumerate(tsne_data):\n",
    "    activation_cls = ActivationClassifier(item, tsne_kmeans_models[i], classifier_str, data[\"x\"], data[\"y\"], data[\"train_mask\"], data[\"test_mask\"])\n",
    "    \n",
    "    d = [\"t-SNE reduced\", str(i), str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(paths['KMeans'], i, k, \"t-SNE\")\n",
    "    \n",
    "for i, item in enumerate(pca_data):\n",
    "    activation_cls = ActivationClassifier(item, pca_kmeans_models[i], classifier_str, data[\"x\"], data[\"y\"], data[\"train_mask\"], data[\"test_mask\"])\n",
    "    \n",
    "    d = [\"PCA reduced\", str(i), str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(paths['KMeans'], i, k, \"PCA\")\n",
    "    \n",
    "for i, item in enumerate(umap_data):\n",
    "    activation_cls = ActivationClassifier(item, umap_kmeans_models[i], classifier_str, data[\"x\"], data[\"y\"], data[\"train_mask\"], data[\"test_mask\"])\n",
    "    \n",
    "    d = [\"UMAP reduced\", str(i), str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(paths['KMeans'], i, k, \"UMAP\")\n",
    "    \n",
    "plot_completeness_table(\"k-Means\", \"Logistic Regression\", completeness_scores, paths['KMeans'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-grammar",
   "metadata": {},
   "source": [
    "### Using Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-visiting",
   "metadata": {},
   "source": [
    "##### Using Ward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-strain",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classifier_str = \"decision_tree\"\n",
    "\n",
    "completeness_scores = []\n",
    "\n",
    "for i, (key, n) in enumerate(zip(activation_list, raw_n_clusters)):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    activation_cls = ActivationClassifier(activation, raw_hc_models[i], classifier_str, data[\"x\"], data[\"y\"], data[\"train_mask\"], data[\"test_mask\"])\n",
    "    \n",
    "    d = [\"Raw\", str(i), str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(paths[\"Ward\"], i, n, \"raw\")\n",
    "    \n",
    "for i, (item, n) in enumerate(zip(tsne_data, tsne_n_clusters)):\n",
    "    activation_cls = ActivationClassifier(item, tsne_hc_models[i], classifier_str, data[\"x\"], data[\"y\"], data[\"train_mask\"], data[\"test_mask\"])\n",
    "    \n",
    "    d = [\"t-SNE reduced\", str(i), str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(paths[\"Ward\"], i, n, \"t-SNE\")\n",
    "    \n",
    "for i, (item, n) in enumerate(zip(pca_data, pca_n_clusters)):\n",
    "    activation_cls = ActivationClassifier(item, pca_hc_models[i], classifier_str, data[\"x\"], data[\"y\"], data[\"train_mask\"], data[\"test_mask\"])\n",
    "    \n",
    "    d = [\"PCA reduced\", str(i), str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(paths[\"Ward\"], i, n, \"PCA\")\n",
    "    \n",
    "for i, (item, n) in enumerate(zip(umap_data, umap_n_clusters)):\n",
    "    activation_cls = ActivationClassifier(item, umap_hc_models[i], classifier_str, data[\"x\"], data[\"y\"], data[\"train_mask\"], data[\"test_mask\"])\n",
    "    \n",
    "    d = [\"UMAP reduced\", str(i), str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(paths[\"Ward\"], i, n, \"UMAP\")\n",
    "\n",
    "plot_completeness_table(\"HC\", \"Decision Tree\", completeness_scores, paths[\"Ward\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-submission",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classifier_str = \"logistic_regression\"\n",
    "\n",
    "completeness_scores = []\n",
    "\n",
    "for i, key in enumerate(activation_list):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    activation_cls = ActivationClassifier(activation, raw_hc_models[i], classifier_str, data[\"x\"], data[\"y\"], data[\"train_mask\"], data[\"test_mask\"])\n",
    "    \n",
    "    d = [\"Raw\", str(i), str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(paths[\"Ward\"], i, n, \"raw\")\n",
    "    \n",
    "for i, item in enumerate(tsne_data):\n",
    "    activation_cls = ActivationClassifier(item, tsne_hc_models[i], classifier_str, data[\"x\"], data[\"y\"], data[\"train_mask\"], data[\"test_mask\"])\n",
    "    \n",
    "    d = [\"t-SNE reduced\", str(i), str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(paths[\"Ward\"], i, n, \"t-SNE\")\n",
    "    \n",
    "for i, item in enumerate(pca_data):\n",
    "    activation_cls = ActivationClassifier(item, pca_hc_models[i], classifier_str, data[\"x\"], data[\"y\"], data[\"train_mask\"], data[\"test_mask\"])\n",
    "    \n",
    "    d = [\"PCA reduced\", str(i), str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(paths[\"Ward\"], i, n, \"PCA\")\n",
    "    \n",
    "for i, (item, n) in enumerate(zip(umap_data, umap_n_clusters)):\n",
    "    activation_cls = ActivationClassifier(item, umap_hc_models[i], classifier_str, data[\"x\"], data[\"y\"], data[\"train_mask\"], data[\"test_mask\"])\n",
    "    \n",
    "    d = [\"UMAP reduced\", str(i), str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(paths[\"Ward\"], i, n, \"UMAP\")\n",
    "\n",
    "plot_completeness_table(\"HC\", \"Logistic Regression\", completeness_scores, paths[\"Ward\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-therapy",
   "metadata": {},
   "source": [
    "##### Using DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-perfume",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classifier_str = \"decision_tree\"\n",
    "\n",
    "completeness_scores = []\n",
    "\n",
    "for i, key in enumerate(activation_list):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    \n",
    "    dbscan_model, n = raw_dbscan_models[i]\n",
    "    activation_cls = ActivationClassifier(activation, dbscan_model, classifier_str, data[\"x\"], data[\"y\"], data[\"train_mask\"], data[\"test_mask\"])\n",
    "    \n",
    "    d = [\"raw\", str(i), str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(paths[\"DBSCAN\"], i, n, \"raw\")\n",
    "    \n",
    "for i, item in enumerate(tsne_data):\n",
    "    dbscan_model, n = tsne_dbscan_models[i]\n",
    "    activation_cls = ActivationClassifier(item, dbscan_model, classifier_str, data[\"x\"], data[\"y\"], data[\"train_mask\"], data[\"test_mask\"])\n",
    "    \n",
    "    d = [\"t-SNE reduced\", str(i), str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(paths[\"DBSCAN\"], i, n, \"t-SNE\")\n",
    "    \n",
    "for i, item in enumerate(pca_data):\n",
    "    dbscan_model, n = pca_dbscan_models[i]\n",
    "    activation_cls = ActivationClassifier(item, dbscan_model, classifier_str, data[\"x\"], data[\"y\"], data[\"train_mask\"], data[\"test_mask\"])\n",
    "    \n",
    "    d = [\"PCA reduced\", str(i), str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(paths[\"Ward\"], i, n, \"PCA\")\n",
    "    \n",
    "for i, item in enumerate(umap_data):\n",
    "    dbscan_model, n = umap_dbscan_models[i]\n",
    "    activation_cls = ActivationClassifier(item, dbscan_model, classifier_str, data[\"x\"], data[\"y\"], data[\"train_mask\"], data[\"test_mask\"])\n",
    "    \n",
    "    d = [\"UMAP reduced\", str(i), str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(paths[\"DBSCAN\"], i, n, \"UMAP\")\n",
    "\n",
    "plot_completeness_table(\"DBSCAN\", \"Decision Tree\", completeness_scores, paths[\"DBSCAN\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-jones",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classifier_str = \"logistic_regression\"\n",
    "\n",
    "completeness_scores = []\n",
    "\n",
    "for i, key in enumerate(activation_list):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    dbscan_model, n = raw_dbscan_models[i]\n",
    "    activation_cls = ActivationClassifier(activation, dbscan_model, classifier_str, data[\"x\"], data[\"y\"], data[\"train_mask\"], data[\"test_mask\"])\n",
    "    \n",
    "    d = [\"raw\", str(i), str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(paths[\"DBSCAN\"], i, n, \"raw\")\n",
    "    \n",
    "for i, item in enumerate(tsne_data):\n",
    "    dbscan_model, n = tsne_dbscan_models[i]\n",
    "    activation_cls = ActivationClassifier(item, dbscan_model, classifier_str, data[\"x\"], data[\"y\"], data[\"train_mask\"], data[\"test_mask\"])\n",
    "    \n",
    "    d = [\"t-SNE reduced\", str(i), str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(paths[\"DBSCAN\"], i, n, \"t-SNE\")\n",
    "    \n",
    "for i, item in enumerate(pca_data):\n",
    "    dbscan_model, n = pca_dbscan_models[i]\n",
    "    activation_cls = ActivationClassifier(item, dbscan_model, classifier_str, data[\"x\"], data[\"y\"], data[\"train_mask\"], data[\"test_mask\"])\n",
    "    \n",
    "    d = [\"PCA reduced\", str(i), str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(paths[\"DBSCAN\"], i, n, \"PCA\")\n",
    "    \n",
    "for i, (item, n) in enumerate(zip(umap_data, umap_n_clusters)):\n",
    "    dbscan_model, n = umap_dbscan_models[i]\n",
    "    activation_cls = ActivationClassifier(item, dbscan_model, classifier_str, data[\"x\"], data[\"y\"], data[\"train_mask\"], data[\"test_mask\"])\n",
    "    \n",
    "    d = [\"UMAP reduced\", str(i), str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(paths[\"DBSCAN\"], i, n, \"UMAP\")\n",
    "\n",
    "plot_completeness_table(\"DBSCAN\", \"Logistic Regression\", completeness_scores, paths[\"DBSCAN\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-growing",
   "metadata": {},
   "source": [
    "# Graph Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-warrant",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-integration",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "graph_scores = []\n",
    "view = 3\n",
    "max_num_nodes = 15\n",
    "\n",
    "for i, key in enumerate(activation_list):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    distances = get_node_distances(raw_kmeans_models[i], activation)\n",
    "\n",
    "    for k_idx in range(k):\n",
    "        top_indices = np.argsort(distances[:, k_idx])[::][:view]\n",
    "        top_graphs, _, _, _ = get_top_subgraphs(top_indices, data['y'], edges, num_expansions)\n",
    "        \n",
    "        score = calc_graph_similarity(top_graphs, max_num_nodes, view)\n",
    "        print(score)\n",
    "        \n",
    "        d = [\"k-Means\", \"raw\", str(i), str(k_idx), str(score)]\n",
    "        graph_scores.append(d)\n",
    "        \n",
    "    plot_samples(raw_kmeans_models[i], activation, data['y'], i, k, \"k-Means\", \"raw\", view, edges, num_expansions, paths['KMeans'])\n",
    "        \n",
    "        \n",
    "for i, item in enumerate(tsne_data):    \n",
    "    distances = get_node_distances(tsne_kmeans_models[i], item)\n",
    "    \n",
    "    for k_idx in range(k):\n",
    "        top_indices = np.argsort(distances[:, k_idx])[::][:view]\n",
    "        top_graphs, _, _, _ = get_top_subgraphs(top_indices, data['y'], edges, num_expansions)\n",
    "\n",
    "        score = calc_graph_similarity(top_graphs, max_num_nodes, view)\n",
    "        print(score)\n",
    "        \n",
    "        d = [\"k-Means\", \"t-SNE\", str(i), str(k_idx), str(score)]\n",
    "        graph_scores.append(d)\n",
    "        \n",
    "    plot_samples(tsne_kmeans_models[i], item, data['y'], i, k, \"k-Means\", \"t-SNE\", view, edges, num_expansions, paths['KMeans'])\n",
    "    \n",
    "for i, item in enumerate(pca_data):\n",
    "    distances = get_node_distances(pca_kmeans_models[i], item)\n",
    "    \n",
    "    for k_idx in range(k):\n",
    "        top_indices = np.argsort(distances[:, k_idx])[::][:view]\n",
    "        top_graphs, _, _, _ = get_top_subgraphs(top_indices, data['y'], edges, num_expansions)\n",
    "        \n",
    "        score = calc_graph_similarity(top_graphs, max_num_nodes, view)\n",
    "        print(score)\n",
    "        \n",
    "        d = [\"k-Means\", \"PCA\", str(i), str(k_idx), str(score)]\n",
    "        graph_scores.append(d)\n",
    "        \n",
    "    plot_samples(pca_kmeans_models[i], item, data['y'], i, k, \"k-Means\", \"PCA\", view, edges, num_expansions, paths['KMeans'])\n",
    "\n",
    "\n",
    "for i, item in enumerate(umap_data):\n",
    "    distances = get_node_distances(umap_kmeans_models[i], item)\n",
    "    \n",
    "    for k_idx in range(k):\n",
    "        top_indices = np.argsort(distances[:, k_idx])[::][:view]\n",
    "        top_graphs, _, _, _ = get_top_subgraphs(top_indices, data['y'], edges, num_expansions)\n",
    "        \n",
    "        score = calc_graph_similarity(top_graphs, max_num_nodes, view)\n",
    "        print(score)\n",
    "        \n",
    "        d = [\"k-Means\", \"UMAP\", str(i), str(k_idx), str(score)]\n",
    "        graph_scores.append(d)\n",
    "        \n",
    "    plot_samples(umap_kmeans_models[i], item, data['y'], i, k, \"k-Means\", \"UMAP\", view, edges, num_expansions, paths['KMeans'])\n",
    "    \n",
    "plot_graph_similarity_table(\"k-Means\", graph_scores, paths['KMeans'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-filename",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "graph_scores = []\n",
    "\n",
    "for i, (key, n) in enumerate(zip(activation_list, raw_n_clusters)):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    pred_labels = raw_hc_models[i].fit_predict(activation)\n",
    "    d_item = (activation, pred_labels)\n",
    "    distances = get_node_distances(raw_hc_models[i], d_item)\n",
    "    \n",
    "    for k_idx in range(n):        \n",
    "        top_indices = np.argsort(distances[k_idx])[::][:view]\n",
    "        top_graphs, _, _, _ = get_top_subgraphs(top_indices, data['y'], edges, num_expansions)\n",
    "                \n",
    "        score = calc_graph_similarity(top_graphs, max_num_nodes, view)\n",
    "        print(score)\n",
    "        \n",
    "        d = [\"HC\", \"raw\", str(i), str(k_idx), str(score)]\n",
    "        graph_scores.append(d)\n",
    "        \n",
    "    plot_samples(raw_hc_models[i], d_item, data[\"y\"], i, n, \"HC\", \"raw\", view, edges, num_expansions, paths['Ward'])\n",
    "        \n",
    "        \n",
    "for i, (item, n) in enumerate(zip(tsne_data, tsne_n_clusters)): \n",
    "    pred_labels = tsne_hc_models[i].fit_predict(item)\n",
    "    d_item = (item, pred_labels)\n",
    "    distances = get_node_distances(tsne_hc_models[i], d_item)\n",
    "    \n",
    "    for k_idx in range(n):\n",
    "        top_indices = np.argsort(distances[k_idx])[::][:view]\n",
    "        top_graphs, _, _, _ = get_top_subgraphs(top_indices, data['y'], edges, num_expansions)\n",
    "        \n",
    "        score = calc_graph_similarity(top_graphs, max_num_nodes, view)\n",
    "        print(score)\n",
    "        \n",
    "        d = [\"HC\", \"t-SNE\", str(i), str(k_idx), str(score)]\n",
    "        graph_scores.append(d)\n",
    "        \n",
    "    plot_samples(tsne_hc_models[i], d_item, data[\"y\"], i, n, \"HC\", \"t-SNE\", view, edges, num_expansions, paths['Ward'])\n",
    "        \n",
    "\n",
    "        \n",
    "for i, (item, n) in enumerate(zip(pca_data, pca_n_clusters)):\n",
    "    pred_labels = pca_hc_models[i].fit_predict(item)\n",
    "    d_item = (item, pred_labels)\n",
    "    distances = get_node_distances(pca_hc_models[i], d_item)\n",
    "\n",
    "    for k_idx in range(n):\n",
    "        top_indices = np.argsort(distances[k_idx])[::][:view]\n",
    "        top_graphs, _, _, _ = get_top_subgraphs(top_indices, data['y'], edges, num_expansions)\n",
    "        \n",
    "        score = calc_graph_similarity(top_graphs, max_num_nodes, view)\n",
    "        print(score)\n",
    "        \n",
    "        d = [\"HC\", \"PCA\", str(i), str(k_idx), str(score)]\n",
    "        graph_scores.append(d)\n",
    "        \n",
    "    plot_samples(pca_hc_models[i], d_item, data[\"y\"], i, n, \"HC\", \"PCA\", view, edges, num_expansions, paths['Ward'])\n",
    "    \n",
    "\n",
    "for i, (item, n) in enumerate(zip(umap_data, umap_n_clusters)):\n",
    "    pred_labels = umap_hc_models[i].fit_predict(item)\n",
    "    d_item = (item, pred_labels)\n",
    "    distances = get_node_distances(umap_hc_models[i], d_item)\n",
    "\n",
    "    for k_idx in range(n):\n",
    "        top_indices = np.argsort(distances[k_idx])[::][:view]\n",
    "        top_graphs, _, _, _ = get_top_subgraphs(top_indices, data['y'], edges, num_expansions)\n",
    "        \n",
    "        score = calc_graph_similarity(top_graphs, max_num_nodes, view)\n",
    "        print(score)\n",
    "        \n",
    "        d = [\"HC\", \"UMAP\", str(i), str(k_idx), str(score)]\n",
    "        graph_scores.append(d)\n",
    "        \n",
    "    plot_samples(umap_hc_models[i], d_item, data[\"y\"], i, n, \"HC\", \"UMAP\", view, edges, num_expansions, paths['Ward'])\n",
    "        \n",
    "    \n",
    "plot_graph_similarity_table(\"HC\", graph_scores, paths['Ward'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-china",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "graph_scores = []\n",
    "\n",
    "for i, key in enumerate(activation_list):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    \n",
    "    dbscan_model, n = raw_dbscan_models[i]\n",
    "    distances = get_node_distances(dbscan_model, raw_dbscan_ds[i])\n",
    "\n",
    "    for k_idx in range(n):\n",
    "        top_indices = np.argsort(distances[:, k_idx])[::][:view]\n",
    "        top_graphs, _, _, _ = get_top_subgraphs(top_indices, data['y'], edges, num_expansions)\n",
    "        \n",
    "        score = calc_graph_similarity(top_graphs, max_num_nodes, view)\n",
    "        print(score)\n",
    "        \n",
    "        d = [\"DBSCAN\", \"raw\", str(i), str(k_idx), str(score)]\n",
    "        graph_scores.append(d)\n",
    "        \n",
    "    plot_samples(dbscan_model, raw_dbscan_ds[i], data['y'], i, n, \"DBSCAN\", \"raw\", view, edges, num_expansions, paths['DBSCAN'])\n",
    "        \n",
    "for i, item in enumerate(tsne_data):  \n",
    "    dbscan_model, n = tsne_dbscan_models[i]\n",
    "    distances = get_node_distances(dbscan_model, tsne_dbscan_ds[i])\n",
    "    \n",
    "    for k_idx in range(n):\n",
    "        top_indices = np.argsort(distances[:, k_idx])[::][:view]\n",
    "        top_graphs, _, _, _ = get_top_subgraphs(top_indices, data['y'], edges, num_expansions)\n",
    "\n",
    "        score = calc_graph_similarity(top_graphs, max_num_nodes, view)\n",
    "        print(score)\n",
    "        \n",
    "        d = [\"DBSCAN\", \"t-SNE\", str(i), str(k_idx), str(score)]\n",
    "        graph_scores.append(d)\n",
    "        \n",
    "    plot_samples(dbscan_model, tsne_dbscan_ds[i], data['y'], i, n, \"DBSCAN\", \"t-SNE\", view, edges, num_expansions, paths['DBSCAN'])\n",
    "    \n",
    "for i, item in enumerate(pca_data):\n",
    "    dbscan_model, n = pca_dbscan_models[i]\n",
    "    distances = get_node_distances(dbscan_model, pca_dbscan_ds[i])\n",
    "    \n",
    "    for k_idx in range(n):\n",
    "        top_indices = np.argsort(distances[:, k_idx])[::][:view]\n",
    "        top_graphs, _, _, _ = get_top_subgraphs(top_indices, data['y'], edges, num_expansions)\n",
    "        \n",
    "        score = calc_graph_similarity(top_graphs, max_num_nodes, view)\n",
    "        print(score)\n",
    "        \n",
    "        d = [\"DBSCAN\", \"PCA\", str(i), str(k_idx), str(score)]\n",
    "        graph_scores.append(d)\n",
    "        \n",
    "    plot_samples(dbscan_model, pca_dbscan_ds[i], data['y'], i, n, \"DBSCAN\", \"PCA\", view, edges, num_expansions, paths['DBSCAN'])\n",
    "\n",
    "\n",
    "for i, item in enumerate(umap_data):\n",
    "    dbscan_model, n = umap_dbscan_models[i]\n",
    "    distances = get_node_distances(dbscan_model, umap_dbscan_ds[i])\n",
    "    \n",
    "    for k_idx in range(n):\n",
    "        top_indices = np.argsort(distances[:, k_idx])[::][:view]\n",
    "        top_graphs, _, _, _ = get_top_subgraphs(top_indices, data['y'], edges, num_expansions)\n",
    "        \n",
    "        score = calc_graph_similarity(top_graphs, max_num_nodes, view)\n",
    "        print(score)\n",
    "        \n",
    "        d = [\"DBSCAN\", \"UMAP\", str(i), str(k_idx), str(score)]\n",
    "        graph_scores.append(d)\n",
    "        \n",
    "    plot_samples(dbscan_model, umap_dbscan_ds[i], data['y'], i, n, \"DBSCAN\", \"UMAP\", view, edges, num_expansions, paths['DBSCAN'])\n",
    "    \n",
    "plot_graph_similarity_table(\"DBSCAN\", graph_scores, paths['DBSCAN'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-tanzania",
   "metadata": {},
   "source": [
    "# GNNExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-peripheral",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_idx = 514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-speed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain using k-Means\n",
    "edges = data['edge_list'].numpy()\n",
    "\n",
    "# get predicted cluster label - visualise top representations in cluster\n",
    "activation_key = 'conv3'\n",
    "layer_idx = 3\n",
    "\n",
    "# get concept number\n",
    "activations = torch.squeeze(activation_list[activation_key]).detach().numpy()\n",
    "concepts = raw_kmeans_models[layer_idx].predict(activations) \n",
    "\n",
    "# get top example for concept/cluster\n",
    "concept = concepts[node_idx]\n",
    "top_graph = raw_kmeans_sample_graphs[layer_idx][concept][0]\n",
    "color_map = raw_kmeans_sample_feat[layer_idx][concept]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "nx.draw(top_graph, node_color=color_map, with_labels=True, ax=ax)\n",
    "ax.set_title(f\"Top Example of Concept extracted using k-Means for Node {node_idx}\")\n",
    "plt.show()\n",
    "\n",
    "# get closest concept representations to what trying to explain\n",
    "indices_in_cluster = np.argwhere(concepts == concept).flatten()\n",
    "clustered_activations = activations[indices_in_cluster]\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "nearest_neighbours = NearestNeighbors(n_neighbors=5).fit(clustered_activations)\n",
    "neighbours = nearest_neighbours.kneighbors(np.expand_dims(activations[node_idx], axis=0), 5)\n",
    "\n",
    "neighbours = indices_in_cluster[neighbours[1]].flatten()\n",
    "tg, cm, labels, _ = get_top_subgraphs(neighbours, data['y'], edges, num_expansions)\n",
    "\n",
    "fig, axs = plt.subplots(1, len(neighbours), figsize=(14, 6))\n",
    "fig.suptitle(f\"Nearest Concept representations extacted using k-Means for Node {node_idx}\")\n",
    "for i, (g, c, l) in enumerate(zip(tg, cm, labels)):\n",
    "    nx.draw(g, node_color=c, with_labels=True, ax=axs[i])\n",
    "    ax.set_title(f\"label {l}\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_idx = 698\n",
    "\n",
    "# get predicted cluster label - visualise top representations in cluster\n",
    "activation_layer = 'conv3'\n",
    "layer_idx = 3\n",
    "n = 14\n",
    "\n",
    "# get top surrouning examples\n",
    "activations = torch.squeeze(activation_list[activation_key]).detach().numpy()\n",
    "hc = AgglomerativeClustering(n_clusters=n, affinity='euclidean', linkage='ward')\n",
    "concepts = hc.fit_predict(activations)\n",
    "\n",
    "d = (activations, concepts)\n",
    "\n",
    "concept = concepts[node_idx]\n",
    "\n",
    "def get_top_example(clustering_model, data, y, edges, cluster_num, num_expansions):\n",
    "    res_sorted = get_node_distances(clustering_model, data)\n",
    "    \n",
    "    if isinstance(clustering_model, AgglomerativeClustering) or isinstance(clustering_model, DBSCAN):\n",
    "        print(res_sorted.shape)\n",
    "        distances = res_sorted[cluster_num]\n",
    "    elif isinstance(clustering_model, KMeans):\n",
    "        distances = res_sorted[:, cluster_num]\n",
    "            \n",
    "    top_index = np.argsort(distances)[::][0]\n",
    "    tg, cm, labels, _ = get_top_subgraphs([top_index], y, edges, num_expansions)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.suptitle(f\"Top Example of Concept extracted using HC for Node {node_idx}\")\n",
    "    \n",
    "    nx.draw(tg[0], node_color=cm[0], with_labels=True, ax=ax)\n",
    "    ax.set_title(f\"label {labels[0]}\", fontsize=14)\n",
    "\n",
    "    \n",
    "edges = data['edge_list'].numpy()\n",
    "# get top example for concept/cluster\n",
    "get_top_example(hc, d, data['y'], edges, concept, num_expansions)\n",
    "\n",
    "# get closest concept representations to what trying to explain\n",
    "indices_in_cluster = np.argwhere(concepts == concept).flatten()\n",
    "clustered_activations = activations[indices_in_cluster]\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "nearest_neighbours = NearestNeighbors(n_neighbors=5).fit(clustered_activations)\n",
    "neighbours = nearest_neighbours.kneighbors(np.expand_dims(activations[node_idx], axis=0), 5)\n",
    "\n",
    "neighbours = indices_in_cluster[neighbours[1]].flatten()\n",
    "tg, cm, labels, _ = get_top_subgraphs(neighbours, data['y'], edges, num_expansions)\n",
    "\n",
    "fig, axs = plt.subplots(1, len(neighbours), figsize=(14, 6))\n",
    "fig.suptitle(f\"Nearest Concept representations extacted using HC for Node {node_idx}\")\n",
    "for i, (g, c, l) in enumerate(zip(tg, cm, labels)):\n",
    "    nx.draw(g, node_color=c, with_labels=True, ax=axs[i])\n",
    "    ax.set_title(f\"label {l}\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-leave",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # node_idx = 698\n",
    "\n",
    "# # Explain using DBSCAN\n",
    "# eps = 0.1\n",
    "# min_samples = 3\n",
    "\n",
    "# # get predicted cluster label - visualise top representations in cluster\n",
    "# activation_layer = 2\n",
    "# layer_idx = 3\n",
    "\n",
    "# # get top surrouning examples\n",
    "# activations = umap_data[activation_layer]\n",
    "# dbscan_model = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "# concepts = dbscan_model.fit_predict(activations)\n",
    "\n",
    "# num_cluster = len(np.unique(concepts))\n",
    "# print(\"Num clusters: \", num_cluster)\n",
    "# d = (activations, concepts)\n",
    "\n",
    "# concept = concepts[node_idx]\n",
    "\n",
    "# def get_top_example(clustering_model, data, y, edges, cluster_num, num_expansions):\n",
    "#     res_sorted = get_node_distances(clustering_model, data)\n",
    "    \n",
    "#     if isinstance(clustering_model, AgglomerativeClustering) or isinstance(clustering_model, DBSCAN):\n",
    "#         print(res_sorted.shape)\n",
    "#         distances = res_sorted[cluster_num]\n",
    "#     elif isinstance(clustering_model, KMeans):\n",
    "#         distances = res_sorted[:, cluster_num]\n",
    "            \n",
    "#     top_index = np.argsort(distances)[::][0]\n",
    "#     tg, cm, labels = get_top_subgraphs([top_index], y, edges, num_expansions)\n",
    "\n",
    "#     fig, ax = plt.subplots()\n",
    "#     fig.suptitle(\"Top Example of Concept extracted using DBSCAN for Node 462\")\n",
    "    \n",
    "#     nx.draw(tg[0], node_color=cm[0], with_labels=True, ax=ax)\n",
    "#     ax.set_title(f\"label {labels[0]}\", fontsize=14)\n",
    "\n",
    "    \n",
    "# edges = data['edge_list'].numpy()\n",
    "# # get top example for concept/cluster\n",
    "# get_top_example(dbscan_model, d, data['y'], edges, concept, 1)\n",
    "\n",
    "# # get closest concept representations to what trying to explain\n",
    "# indices_in_cluster = np.argwhere(concepts == concept).flatten()\n",
    "# clustered_activations = activations[indices_in_cluster]\n",
    "\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "# nearest_neighbours = NearestNeighbors(n_neighbors=5).fit(clustered_activations)\n",
    "# neighbours = nearest_neighbours.kneighbors(np.expand_dims(activations[node_idx], axis=0), 5)\n",
    "\n",
    "# neighbours = indices_in_cluster[neighbours[1]].flatten()\n",
    "# tg, cm, labels = get_top_subgraphs(neighbours, data['y'], edges, num_expansions)\n",
    "\n",
    "# fig, axs = plt.subplots(1, len(neighbours), figsize=(14, 6))\n",
    "# fig.suptitle(\"Nearest Concept representations extacted using DBSCAN for Node 462\")\n",
    "# for i, (g, c, l) in enumerate(zip(tg, cm, labels)):\n",
    "#     nx.draw(g, node_color=c, with_labels=True, ax=axs[i])\n",
    "#     ax.set_title(f\"label {label}\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-louisiana",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# convert to edge format\n",
    "edges = data['edges'].t().contiguous()\n",
    "\n",
    "explainer = GNNExplainer(model, epochs=1000, return_type='log_prob', log=True)\n",
    "node_feat_mask, edge_mask = explainer.explain_node(node_idx, data['x'], data['edges'])\n",
    "\n",
    "ax, G = explainer.visualize_subgraph(node_idx, data['edges'], edge_mask, y=data['y'], threshold=0.8)\n",
    "plt.title(f\"GNNExplainer explanation for Node {node_idx}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-course",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clustering_env",
   "language": "python",
   "name": "clustering_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
