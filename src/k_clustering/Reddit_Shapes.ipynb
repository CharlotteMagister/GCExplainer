{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pleasant-exploration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x104d93150>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import networkx as nx\n",
    "\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree, to_dense_adj, convert\n",
    "from torch_geometric.data import DataLoader, DenseDataLoader\n",
    "from torch_geometric.nn import GNNExplainer, GCNConv\n",
    "from torch_geometric.nn import global_mean_pool, GlobalAttention\n",
    "\n",
    "from sklearn.cluster import KMeans, MeanShift, DBSCAN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn import tree, linear_model\n",
    "\n",
    "import scipy.cluster.hierarchy as hierarchy\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "from torch_geometric.nn import GNNExplainer\n",
    "\n",
    "from utilities import *\n",
    "from heuristics import *\n",
    "from activation_classifier import *\n",
    "\n",
    "set_rc_params()\n",
    "\n",
    "np.random.seed(3)\n",
    "torch.manual_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "respiratory-approval",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Graph Classification\n",
      "Number of graphs:  2000\n",
      "Number of features: 1\n",
      "Class split - Training 0: 792 1:808, Test 0: 208 1: 192\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "\n",
    "path = \"output/reddit/\"\n",
    "path_tsne = os.path.join(path, \"TSNE\")\n",
    "path_pca = os.path.join(path, \"PCA\")\n",
    "path_kmeans = os.path.join(path, f\"{k}_KMeans\")\n",
    "path_hc = os.path.join(path, f\"HC\")\n",
    "os.makedirs(path, exist_ok=True)\n",
    "os.makedirs(path_tsne, exist_ok=True)\n",
    "os.makedirs(path_pca, exist_ok=True)\n",
    "os.makedirs(path_kmeans, exist_ok=True)\n",
    "os.makedirs(path_hc, exist_ok=True)\n",
    "\n",
    "batch_size = 64\n",
    "graphs = load_real_data(\"Reddit_Binary\")\n",
    "train_loader, test_loader, full_loader = prepare_real_data(graphs, 0.8, batch_size)\n",
    "labels = next(iter(full_loader)).y\n",
    "\n",
    "model = Reddit_GCN(graphs.num_node_features, graphs.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-shame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 545, Train Loss: 0.41667, Test Loss: 0.36928, Train Acc: 0.80812, Test Acc: 0.82000\r"
     ]
    }
   ],
   "source": [
    "load_pretrained = False\n",
    "\n",
    "if load_pretrained:\n",
    "    model.load_state_dict(torch.load(\"models/mutagenicity_model.pkl\"))\n",
    "    model.eval()\n",
    "\n",
    "    with open(\"models/mutagenicity_activation.txt\", 'rb') as file:\n",
    "        activation_list = pickle.loads(file.read())\n",
    "\n",
    "else:\n",
    "    model.apply(weights_init)\n",
    "    train_graph_class(model, train_loader, test_loader, full_loader, 2000, 0.001, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-lending",
   "metadata": {},
   "source": [
    "# TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSNE conversion\n",
    "tsne_models = []\n",
    "tsne_data = []\n",
    "for layer_num, key in enumerate(activation_list):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    tsne_model = TSNE(n_components=2)\n",
    "    d = tsne_model.fit_transform(activation)\n",
    "    plot_activation_space(d, labels, \"TSNE-Reduced\", key, path_tsne, \"(coloured by labels)\")\n",
    "    \n",
    "    tsne_models.append(tsne_model)\n",
    "    tsne_data.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-sellers",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA conversion\n",
    "pca_models = []\n",
    "pca_data = []\n",
    "for layer_num, key in enumerate(activation_list):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    pca_model = PCA(n_components=2)\n",
    "    d = pca_model.fit_transform(activation)\n",
    "    plot_activation_space(d, labels, \"PCA-Reduced\", layer_num, path_pca, \"(coloured by labels)\")\n",
    "    \n",
    "    pca_models.append(pca_model)\n",
    "    pca_data.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-minnesota",
   "metadata": {},
   "source": [
    "# Perform KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes_view = 5\n",
    "num_expansions = 2\n",
    "\n",
    "dataset_data = next(iter(full_loader))\n",
    "edges = dataset_data.edge_index.transpose(0, 1).detach().numpy()\n",
    "y = dataset_data.y\n",
    "\n",
    "raw_sample_graphs = []\n",
    "raw_sample_feat = []\n",
    "raw_kmeans_models = []\n",
    "for layer_num, key in enumerate(activation_list):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    kmeans_model = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans_model = kmeans_model.fit(activation)\n",
    "    pred_labels = kmeans_model.predict(activation)\n",
    "        \n",
    "    plot_clusters(tsne_data[layer_num], pred_labels, \"KMeans\", k, key, path_kmeans, \"Raw\", \"_TSNE\", \"(TSNE Reduced)\")\n",
    "    plot_clusters(pca_data[layer_num], pred_labels, \"KMeans\", k, key, path_kmeans, \"Raw\", \"_PCA\", \"(PCA Reduced)\")\n",
    "    sample_graphs, sample_feat = plot_samples(kmeans_model, activation, y, key, k, \"KMeans-Raw\", num_nodes_view, edges, num_expansions, path_kmeans, dataset_data)\n",
    "    \n",
    "    raw_sample_graphs.append(sample_graphs)\n",
    "    raw_sample_feat.append(sample_feat)\n",
    "    raw_kmeans_models.append(kmeans_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-developer",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_sample_graphs = []\n",
    "tsne_sample_feat = []\n",
    "tsne_kmeans_models = []\n",
    "for layer_num, (key, item) in enumerate(zip(activation_list, tsne_data)):\n",
    "    kmeans_model = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans_model = kmeans_model.fit(item)\n",
    "    pred_labels = kmeans_model.predict(item)\n",
    "        \n",
    "    plot_clusters(item, pred_labels, \"KMeans\", k, key, path_kmeans, \"TSNE\")\n",
    "    sample_graphs, sample_feat = plot_samples(kmeans_model, item, y, key, k, \"KMeans-TSNE\", num_nodes_view, edges, num_expansions, path_kmeans, dataset_data)\n",
    "    \n",
    "    tsne_sample_graphs.append(sample_graphs)\n",
    "    tsne_sample_feat.append(sample_feat)\n",
    "    tsne_kmeans_models.append(kmeans_model)\n",
    "    \n",
    "pca_sample_graphs = []\n",
    "pca_sample_feat = []\n",
    "pca_kmeans_models = []\n",
    "for key, item in zip(activation_list, pca_data):\n",
    "    kmeans_model = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans_model = kmeans_model.fit(item)\n",
    "    pred_labels = kmeans_model.predict(item)\n",
    "        \n",
    "    plot_clusters(item, pred_labels, \"KMeans\", k, key, path_kmeans, \"PCA\")\n",
    "    sample_graphs, sample_feat = plot_samples(kmeans_model, item, y, key, k, \"KMeans-PCA\", num_nodes_view, edges, num_expansions, path_kmeans, dataset_data)\n",
    "    \n",
    "    pca_sample_graphs.append(sample_graphs)\n",
    "    pca_sample_feat.append(sample_feat)\n",
    "    pca_kmeans_models.append(kmeans_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutag_heuristics = Mutag_Heuristics()\n",
    "\n",
    "for layer_num, (key, sample, feat) in enumerate(zip(activation_list, raw_sample_graphs, raw_sample_feat)):\n",
    "    mutag_heuristics.plot_heuristics_table(sample, feat, key, \"KMeans-Raw\", path_kmeans)\n",
    "    \n",
    "for layer_num, (key, sample, feat) in enumerate(zip(activation_list, tsne_sample_graphs, tsne_sample_feat)):\n",
    "    mutag_heuristics.plot_heuristics_table(sample, feat, key, \"KMeans-TSNE\", path_kmeans)\n",
    "    \n",
    "for layer_num, (key, sample, feat) in enumerate(zip(activation_list, pca_sample_graphs, pca_sample_feat)):\n",
    "    mutag_heuristics.plot_heuristics_table(sample, feat, key, \"KMeans-PCA\", path_kmeans)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-allergy",
   "metadata": {},
   "source": [
    "# Perform Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_num, key in enumerate(activation_list):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    plot_dendrogram(activation, \"Raw\", layer_num, path_hc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_n_clusters = [3, 3, 18, 20]\n",
    "\n",
    "raw_sample_graphs = []\n",
    "raw_sample_feat = []\n",
    "raw_hc_models = []\n",
    "for layer_num, (key, n) in enumerate(zip(activation_list, raw_n_clusters)):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    hc = AgglomerativeClustering(n_clusters=n, affinity='euclidean', linkage='average')\n",
    "    pred_labels = hc.fit_predict(activation)\n",
    "    \n",
    "    d = (activation, pred_labels)\n",
    "    plot_clusters(tsne_data[layer_num], pred_labels, \"HC\", n, layer_num, path_hc, \"Raw\", \"_TSNE\", \"(TSNE Reduced)\")\n",
    "    plot_clusters(pca_data[layer_num], pred_labels, \"HC\", n, layer_num, path_hc, \"Raw\", \"_PCA\", \"(PCA Reduced)\")\n",
    "    sample_graphs, sample_feat = plot_samples(hc, d, y, layer_num, n, \"HC-Raw\", num_nodes_view, edges, num_expansions, path_hc, dataset_data)\n",
    "    \n",
    "    raw_sample_graphs.append(sample_graphs)\n",
    "    raw_sample_feat.append(sample_feat)\n",
    "    raw_hc_models.append(hc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_num, item in enumerate(tsne_data):\n",
    "    plot_dendrogram(item, \"TSNE\", layer_num, path_hc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-tours",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_n_clusters = [7, 12, 20, 20]\n",
    "\n",
    "tsne_sample_graphs = []\n",
    "tsne_sample_feat = []\n",
    "tsne_hc_models = []\n",
    "for layer_num, (item, n) in enumerate(zip(tsne_data, tsne_n_clusters)):\n",
    "    hc = AgglomerativeClustering(n_clusters=n, affinity='euclidean', linkage='average')\n",
    "    pred_labels = hc.fit_predict(item)\n",
    "    \n",
    "    d = (item, pred_labels)\n",
    "    plot_clusters(item, pred_labels, \"HC\", n, layer_num, path_hc, \"TSNE\")\n",
    "    sample_graphs, sample_feat = plot_samples(hc, d, y, layer_num, n, \"HC-TSNE\", num_nodes_view, edges, num_expansions, path_hc, dataset_data)\n",
    "    \n",
    "    tsne_sample_graphs.append(sample_graphs)\n",
    "    tsne_sample_feat.append(sample_feat)\n",
    "    tsne_hc_models.append(hc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_num, item in enumerate(pca_data):\n",
    "    plot_dendrogram(item, \"PCA\", layer_num, path_hc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_n_clusters = [7, 12, 20, 20]\n",
    "\n",
    "pca_sample_graphs = []\n",
    "pca_sample_feat = []\n",
    "pca_hc_models = []\n",
    "for layer_num, (item, n) in enumerate(zip(pca_data, pca_n_clusters)):\n",
    "    hc = AgglomerativeClustering(n_clusters=n, affinity='euclidean', linkage='average')\n",
    "    pred_labels = hc.fit_predict(item)\n",
    "    \n",
    "    d = (item, pred_labels)\n",
    "    plot_clusters(item, pred_labels, \"HC\", n, layer_num, path_hc, \"PCA\")\n",
    "    sample_graphs, sample_feat = plot_samples(hc, d, y, layer_num, n, \"HC-PCA\", num_nodes_view, edges, num_expansions, path_hc, dataset_data)\n",
    "    \n",
    "    pca_sample_graphs.append(sample_graphs)\n",
    "    pca_sample_feat.append(sample_feat)\n",
    "    pca_hc_models.append(hc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_num, (sample, feat) in enumerate(zip(raw_sample_graphs, raw_sample_feat)):\n",
    "    mutag_heuristics.plot_heuristics_table(sample, feat, layer_num, \"HC-RAW\", path_kmeans)\n",
    "    \n",
    "for layer_num, (sample, feat) in enumerate(zip(tsne_sample_graphs, tsne_sample_feat)):\n",
    "    mutag_heuristics.plot_heuristics_table(sample, feat, layer_num, \"HC-TSNE\", path_hc)\n",
    "    \n",
    "for layer_num, (sample, feat) in enumerate(zip(pca_sample_graphs, pca_sample_feat)):\n",
    "    mutag_heuristics.plot_heuristics_table(sample, feat, layer_num, \"HC-PCA\", path_hc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-stevens",
   "metadata": {},
   "source": [
    "# Activation to Concept to Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_str = \"decision_tree\"\n",
    "\n",
    "completeness_scores = []\n",
    "\n",
    "for i, key in enumerate(activation_list):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    activation_cls = ActivationClassifier(activation, raw_kmeans_models[i], classifier_str, graphs, dataset_data.y, edges, i, True)\n",
    "    \n",
    "    d = [\"Kmeans\", \"Raw\", str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(path_kmeans, i, k, \"Raw\")\n",
    "    \n",
    "for i, item in enumerate(tsne_data):\n",
    "    activation_cls = ActivationClassifier(item, tsne_kmeans_models[i], classifier_str, graphs, dataset_data.y, edges, i, True)\n",
    "    \n",
    "    d = [\"Kmeans\", \"TSNE-Reduced\", str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(path_kmeans, i, k, \"TSNE\")\n",
    "    \n",
    "for i, item in enumerate(pca_data):\n",
    "    activation_cls = ActivationClassifier(item, pca_kmeans_models[i], classifier_str, graphs, dataset_data.y, edges, i, True)\n",
    "    \n",
    "    d = [\"Kmeans\", \"PCA-Reduced\", str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(path_kmeans, i, k, \"PCA\")\n",
    "    \n",
    "plot_completeness_table(\"Kmeans\", \"Decision Tree\", completeness_scores, path_kmeans)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_str = \"logistic_regression\"\n",
    "\n",
    "completeness_scores = []\n",
    "\n",
    "for i, key in enumerate(activation_list):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    activation_cls = ActivationClassifier(activation, raw_kmeans_models[i], classifier_str, graphs, dataset_data.y, edges, i, True)\n",
    "    \n",
    "    d = [\"Kmeans\", \"Raw\", str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(path_kmeans, i, k, \"Raw\")\n",
    "    \n",
    "for i, item in enumerate(tsne_data):\n",
    "    activation_cls = ActivationClassifier(item, tsne_kmeans_models[i], classifier_str, graphs, dataset_data.y, edges, i, True)\n",
    "    \n",
    "    d = [\"Kmeans\", \"TSNE-Reduced\", str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(path_kmeans, i, k, \"TSNE\")\n",
    "    \n",
    "for i, item in enumerate(pca_data):\n",
    "    activation_cls = ActivationClassifier(item, pca_kmeans_models[i], classifier_str, graphs, dataset_data.y, edges, i, True)\n",
    "    \n",
    "    d = [\"Kmeans\", \"PCA-Reduced\", str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(path_kmeans, i, k, \"PCA\")\n",
    "    \n",
    "plot_completeness_table(\"Kmeans\", \"Logistic Regression\", completeness_scores, path_kmeans)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_str = \"decision_tree\"\n",
    "\n",
    "completeness_scores = []\n",
    "\n",
    "for i, (key, n) in enumerate(zip(activation_list, raw_n_clusters)):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    activation_cls = ActivationClassifier(activation, raw_hc_models[i], classifier_str, graphs, dataset_data.y, edges, i, True)\n",
    "    \n",
    "    d = [\"HC\", \"Raw\", str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(path_hc, i, n, \"Raw\")\n",
    "    \n",
    "for i, (item, n) in enumerate(zip(tsne_data, tsne_n_clusters)):\n",
    "    activation_cls = ActivationClassifier(item, tsne_hc_models[i], classifier_str, graphs, dataset_data.y, edges, i, True)\n",
    "    \n",
    "    d = [\"HC\", \"TSNE-Reduced\", str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(path_hc, i, n, \"PCA\")\n",
    "    \n",
    "for i, (item, n) in enumerate(zip(pca_data, pca_n_clusters)):\n",
    "    activation_cls = ActivationClassifier(item, pca_hc_models[i], classifier_str, graphs, dataset_data.y, edges, i, True)\n",
    "    \n",
    "    d = [\"HC\", \"PCA-Reduced\", str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(path_hc, i, n, \"PCA\")\n",
    "\n",
    "plot_completeness_table(\"HC\", \"Decision Tree\", completeness_scores, path_hc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_str = \"logistic_regression\"\n",
    "\n",
    "completeness_scores = []\n",
    "\n",
    "for i, key in enumerate(activation_list):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    activation_cls = ActivationClassifier(activation, raw_hc_models[i], classifier_str, graphs, dataset_data.y, edges, i, True)\n",
    "    \n",
    "    d = [\"HC\", \"Raw\", str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(path_hc, i, n, \"Raw\")\n",
    "    \n",
    "for i, item in enumerate(tsne_data):\n",
    "    activation_cls = ActivationClassifier(item, tsne_hc_models[i], classifier_str, graphs, dataset_data.y, edges, i, True)\n",
    "    \n",
    "    d = [\"HC\", \"TSNE-Reduced\", str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(path_hc, i, n, \"TSNE\")\n",
    "    \n",
    "for i, item in enumerate(pca_data):\n",
    "    activation_cls = ActivationClassifier(item, pca_hc_models[i], classifier_str, graphs, dataset_data.y, edges, i, True)\n",
    "    \n",
    "    d = [\"HC\", \"PCA-Reduced\", str(activation_cls.get_classifier_accuracy())]\n",
    "    completeness_scores.append(d)\n",
    "    activation_cls.plot(path_hc, i, n, \"PCA\")\n",
    "\n",
    "plot_completeness_table(\"HC\", \"Logistic Regression\", completeness_scores, path_hc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-product",
   "metadata": {},
   "source": [
    "# Graph Similarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-wisdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_scores = []\n",
    "view = 3\n",
    "max_nodes = 15\n",
    "\n",
    "for i, key in enumerate(activation_list):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    distances = get_node_distances(raw_kmeans_models[i], activation)\n",
    "    \n",
    "    for k_idx in range(k):        \n",
    "        top_indices = np.argsort(distances[:, k_idx])[::][:view]\n",
    "        top_graphs, _, _ = get_top_subgraphs(top_indices, dataset_data.y, edges, num_expansions)\n",
    "        \n",
    "        score = calc_graph_similarity(top_graphs, max_nodes, view)\n",
    "        print(score)\n",
    "        \n",
    "        d = [\"KMeans\", \"Raw\", str(i), str(k_idx), str(score)]\n",
    "        graph_scores.append(d)\n",
    "        \n",
    "    plot_samples(raw_kmeans_models[i], activation, y, i, n, \"KMeans-Raw\", view, edges, num_expansions, path_hc, dataset_data)\n",
    "        \n",
    "        \n",
    "for i, item in enumerate(tsne_data): \n",
    "    distances = get_node_distances(tsne_kmeans_models[i], item)\n",
    "    \n",
    "    for k_idx in range(k):\n",
    "        top_indices = np.argsort(distances[:, k_idx])[::][:view]\n",
    "        top_graphs, _, _ = get_top_subgraphs(top_indices, dataset_data.y, edges, num_expansions)\n",
    "        \n",
    "        score = calc_graph_similarity(top_graphs, max_nodes, view)\n",
    "        print(score)\n",
    "        \n",
    "        d = [\"KMeans\", \"TSNE\", str(i), str(k_idx), str(score)]\n",
    "        graph_scores.append(d)\n",
    "        \n",
    "    plot_samples(tsne_kmeans_models[i], item, dataset_data.y, i, n, \"KMeans-TSNE\", view, edges, num_expansions, path_hc, dataset_data)\n",
    "        \n",
    "\n",
    "        \n",
    "for i, item in enumerate(pca_data):\n",
    "    distances = get_node_distances(pca_kmeans_models[i], item)\n",
    "\n",
    "    for k_idx in range(k):\n",
    "        top_indices = np.argsort(distances[:, k_idx])[::][:view]\n",
    "        top_graphs, _, _ = get_top_subgraphs(top_indices, dataset_data.y, edges, num_expansions)\n",
    "        \n",
    "        score = calc_graph_similarity(top_graphs, max_nodes, view)\n",
    "        print(score)\n",
    "        \n",
    "        d = [\"KMeans\", \"PCA\", str(i), str(k_idx), str(score)]\n",
    "        graph_scores.append(d)\n",
    "        \n",
    "    plot_samples(pca_kmeans_models[i], item, dataset_data.y, i, n, \"KMeans-PCA\", view, edges, num_expansions, path_hc, dataset_data)\n",
    "        \n",
    "    \n",
    "plot_graph_similarity_table(\"HC\", graph_scores, path_hc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_scores = []\n",
    "view = 3\n",
    "max_nodes = 15\n",
    "\n",
    "for i, (key, n) in enumerate(zip(activation_list, raw_n_clusters)):\n",
    "    activation = torch.squeeze(activation_list[key]).detach().numpy()\n",
    "    pred_labels = raw_hc_models[i].fit_predict(activation)\n",
    "    d_item = (activation, pred_labels)\n",
    "    distances = get_node_distances(raw_hc_models[i], d_item)\n",
    "    \n",
    "    for k_idx in range(n):        \n",
    "        top_indices = np.argsort(distances[k_idx])[::][:view]\n",
    "        top_graphs, _, _ = get_top_subgraphs(top_indices, dataset_data.y, edges, num_expansions)\n",
    "        \n",
    "        score = calc_graph_similarity(top_graphs, max_nodes, view)\n",
    "        print(score)\n",
    "        \n",
    "        d = [\"HC\", \"Raw\", str(i), str(k_idx), str(score)]\n",
    "        graph_scores.append(d)\n",
    "        \n",
    "    plot_samples(raw_hc_models[i], d_item, y, i, n, \"HC-Raw\", view, edges, num_expansions, path_hc, dataset_data)\n",
    "        \n",
    "        \n",
    "for i, (item, n) in enumerate(zip(tsne_data, tsne_n_clusters)): \n",
    "    pred_labels = tsne_hc_models[i].fit_predict(item)\n",
    "    d_item = (item, pred_labels)\n",
    "    distances = get_node_distances(tsne_hc_models[i], d_item)\n",
    "    \n",
    "    for k_idx in range(n):\n",
    "        top_indices = np.argsort(distances[k_idx])[::][:view]\n",
    "        top_graphs, _, _ = get_top_subgraphs(top_indices, dataset_data.y, edges, num_expansions)\n",
    "        \n",
    "        score = calc_graph_similarity(top_graphs, max_nodes, view)\n",
    "        print(score)\n",
    "        \n",
    "        d = [\"HC\", \"TSNE\", str(i), str(k_idx), str(score)]\n",
    "        graph_scores.append(d)\n",
    "        \n",
    "    plot_samples(tsne_hc_models[i], d_item, y, i, n, \"HC-TSNE\", view, edges, num_expansions, path_hc, dataset_data)\n",
    "        \n",
    "\n",
    "        \n",
    "for i, (item, n) in enumerate(zip(pca_data, pca_n_clusters)):\n",
    "    pred_labels = pca_hc_models[i].fit_predict(item)\n",
    "    d_item = (item, pred_labels)\n",
    "    distances = get_node_distances(pca_hc_models[i], d_item)\n",
    "\n",
    "    for k_idx in range(n):\n",
    "        top_indices = np.argsort(distances[k_idx])[::][:view]\n",
    "        top_graphs, _, _ = get_top_subgraphs(top_indices, dataset_data.y, edges, num_expansions)\n",
    "        \n",
    "        score = calc_graph_similarity(top_graphs, max_nodes, view)\n",
    "        print(score)\n",
    "        \n",
    "        d = [\"HC\", \"PCA\", str(i), str(k_idx), str(score)]\n",
    "        graph_scores.append(d)\n",
    "        \n",
    "    plot_samples(pca_hc_models[i], d_item, y, i, n, \"HC-PCA\", view, edges, num_expansions, path_hc, dataset_data)\n",
    "        \n",
    "    \n",
    "plot_graph_similarity_table(\"HC\", graph_scores, path_hc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n",
    "\n",
    "g1 = nx.Graph()\n",
    "g1.add_edge(0, 1)\n",
    "g1.add_edge(1, 2)\n",
    "g1.add_edge(2, 3)\n",
    "g1.add_edge(3, 4)\n",
    "g1.add_edge(4, 5)\n",
    "g1.add_edge(5, 6)\n",
    "g1.add_edge(6, 7)\n",
    "g1.add_edge(7, 8)\n",
    "g1.add_edge(8, 9)\n",
    "g1.add_edge(9, 10)\n",
    "g1.add_edge(10, 11)\n",
    "g1.add_edge(11, 12)\n",
    "g1.add_edge(12, 13)\n",
    "\n",
    "nx.draw(g1, node_color=color_map, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-float",
   "metadata": {},
   "source": [
    "# GNNExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-renaissance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_idx = 572\n",
    "\n",
    "# # convert to edge format\n",
    "# edges = edge_list.transpose(0, 1).t().contiguous()\n",
    "\n",
    "# explainer = GNNExplainer2(model, epochs=200, return_type='log_prob', log=True)\n",
    "# node_feat_mask, edge_mask = explainer.explain_node(node_idx, node_data_x, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-siemens",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax, G = explainer.visualize_subgraph(node_idx, edges, edge_mask, y=node_data_y, threshold=0.8)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1) get 3 closest nodes of a cluster\n",
    "# dataset_data = next(iter(full_loader))\n",
    "# edges = dataset_data.edge_index.transpose(0, 1).detach().numpy()\n",
    "\n",
    "# def get_top_graphs(graphs, top_indices):    \n",
    "#     top_graphs = []\n",
    "#     color_maps = []\n",
    "#     graph_labels = []\n",
    "        \n",
    "#     for idx in top_indices:\n",
    "#         graph_data = graphs[int(idx)]\n",
    "#         new_G = nx.Graph()\n",
    "#         new_G.add_edges_from(graph_data.edge_index.transpose(0, 1).numpy())\n",
    "#         top_graphs.append(new_G)\n",
    "        \n",
    "#         color_map = []\n",
    "#         for node, attribute in zip(new_G, graph_data.x.numpy()):\n",
    "#             color_idx = np.argmax(attribute, axis=0)\n",
    "#             color_map.append(color_idx)\n",
    "            \n",
    "#         color_maps.append(color_map)\n",
    "        \n",
    "#         graph_labels.append(graph_data.y)\n",
    "            \n",
    "#     return top_graphs, color_maps, graph_labels\n",
    "\n",
    "\n",
    "# def plot_samples(graphs, clustering_model, layer, data, clustering_type, output):\n",
    "#     num_nodes_view = 5\n",
    "    \n",
    "#     fig, axes = plt.subplots(k, num_nodes_view, figsize=(30,30))\n",
    "#     fig.suptitle(f'Nearest to {clustering_type} Centroid for Layer {layer}', fontsize=40)\n",
    "\n",
    "#     l = list(range(0, k))\n",
    "\n",
    "#     for i, ax_list in zip(l, axes):        \n",
    "#         # get top graphs\n",
    "#         distances = clustering_model.transform(data)[:, i]\n",
    "#         top_indices = np.argsort(distances)[::][:num_nodes_view]\n",
    "#         top_graphs, color_maps, graph_labels = get_top_graphs(graphs, top_indices)\n",
    "        \n",
    "#         for ax, new_G, color_map, g_label in zip(ax_list, top_graphs, color_maps, graph_labels):\n",
    "#             nx.draw(new_G, node_color=color_map, with_labels=True, ax=ax)\n",
    "#             ax.set_title(f\"label {g_label}\", fontsize=14)\n",
    "            \n",
    "#     plt.savefig(os.path.join(path, f\"{output}.png\"))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ActivationClassifier:\n",
    "#     def __init__(self, tsne_data, clustering_model, classifier_type, x, y, edge_list, layer):\n",
    "#         self.tsne_data = tsne_data\n",
    "#         self.clustering_model = clustering_model\n",
    "#         self.classifier_type = classifier_type\n",
    "#         self.x = x.detach().numpy()\n",
    "#         self.y = y.detach().numpy()\n",
    "#         self.edge_list = edge_list\n",
    "#         self.layer = layer\n",
    "        \n",
    "#         self.classifier, self.accuracy = self._train_classifier()\n",
    "        \n",
    "        \n",
    "#     def _train_classifier(self):\n",
    "#         concepts = []\n",
    "#         for node_idx in range(len(node_data_x)):\n",
    "#             concepts.append(self.activation_to_concept(node_idx))\n",
    "          \n",
    "#         if self.classifier_type == 'decision_tree':\n",
    "#             classifier = tree.DecisionTreeClassifier()\n",
    "#             classifier = classifier.fit(concepts, self.y)\n",
    "#         elif self.classifier_type == 'linear_regression':\n",
    "#             classifier = linear_model.LinearRegression()\n",
    "#             classifier = classifier.fit(concepts, self.y)\n",
    "        \n",
    "#         # decision tree accuracy\n",
    "#         accuracy = classifier.score(concepts, self.y)\n",
    "\n",
    "#         return classifier, accuracy\n",
    "    \n",
    "    \n",
    "#     def get_classifier_accuracy(self):\n",
    "#         return self.accuracy\n",
    "    \n",
    "\n",
    "#     def _activation_to_cluster(self, node):\n",
    "#         # apply tsne\n",
    "#         if isinstance(self.clustering_model, KMeans):\n",
    "#             activation = tsne_data[self.layer][node]\n",
    "#             activation = activation.reshape((1, 2))\n",
    "#             cluster = self.clustering_model.predict(activation)\n",
    "            \n",
    "#         elif isinstance(self.clustering_model, AgglomerativeClustering):\n",
    "#             cluster = np.array([y_hc[node]])\n",
    "\n",
    "#         return cluster\n",
    "\n",
    "    \n",
    "#     def _cluster_to_concept(self, cluster):\n",
    "#         concept = cluster\n",
    "\n",
    "#         return concept\n",
    "\n",
    "\n",
    "#     def activation_to_concept(self, node):\n",
    "#         # get cluster for node\n",
    "#         cluster = self._activation_to_cluster(node)\n",
    "\n",
    "#         # return cluster number as substitute of concept\n",
    "#         concept = self._cluster_to_concept(cluster)\n",
    "\n",
    "#         return concept\n",
    "\n",
    "    \n",
    "#     def concept_to_class(self, concept):\n",
    "#         concept = concept.reshape(1, -1)\n",
    "#         pred = self.classifier.predict(concept)\n",
    "\n",
    "#         return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get data\n",
    "# # node_data_x = torch.from_numpy(features).float()\n",
    "# # node_data_y = torch.from_numpy(labels)\n",
    "# # edge_list = torch.from_numpy(edges).transpose(0, 1)\n",
    "\n",
    "# temp = next(iter(full_loader))\n",
    "\n",
    "# node_data_x = temp.x\n",
    "# node_data_y = temp.y\n",
    "# edge_list = temp.edge_index.transpose(0, 1)\n",
    "\n",
    "# # vars\n",
    "# chosen_layer = len(activation_list) - 1\n",
    "# KmeansActivationCls = ActivationClassifier(tsne_data, kmeans_models[chosen_layer], 'decision_tree', node_data_x, node_data_y, edge_list, chosen_layer)\n",
    "\n",
    "# print(\"Decision Tree Accuracy: \", KmeansActivationCls.get_decision_tree_accuracy())\n",
    "\n",
    "# # activation to concept\n",
    "# node_idx = 224\n",
    "# concept = KmeansActivationCls.activation_to_concept(node_idx)\n",
    "# print(\"Predicted concept is: \", concept)\n",
    "\n",
    "# cls = KmeansActivationCls.concept_to_class(concept)\n",
    "# print(\"Predicted class is: \", cls ,\" where real one is: \", node_data_y[node_idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clustering_env",
   "language": "python",
   "name": "clustering_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
